# navigating-ml

With the advent of more data and compute power, we have a unique opportunity to create more intricate algorithms that help address accuracy issues seen in traditional machine learning.  Deep learning allows us to fine tune the fit of an algorithm to its data in an iterative manner, and to evaluate and "feed-back" that information during the training process for a better model.  This results in better models if enough data is provided or in some cases if there's an existing "base model", as is the case in transfer learning, if good quality and highly representative data is provided.

That being said, do you feel like there's just too much to be aware of in the ML and Deep Learning space today?  Concepts like Convolutional Neural Networks, GANs, Neural Style Transfer...and networks like AlexNet, ResNet, or Inception...frameworks like CNTK, TensorFlow, Caffe2, PyTorch...extra layers on top of those like TFLearn, Keras, Gluon, MMLSpark...

> Tip:  Focus on the pipeline or workflow first and iterate on the model after.

If you suspect you are a beginner in this field, do you need some Python knowledge and fast?  If so go to the Getting Started section to load up on resources and once you're comfortable with data manipulation move on to the Level 1 Challenge for Dealing with Images to start building up your traditional machine learning and neural network cred.

Do you grok the basics of ML and perhaps what a fully-connected neural network is?  Have you had some exposure to TensorFlow or PyTorch, but don't yet have deep working knowledge of Convolutional Neural Networks?  In that case, try jumping into the Level 2 section of Dealing with Images.  If it seems a little overwhelming, head back to the Level 1 area.  If it's not challenging enough, move on to the Level 3 section.

Maybe you're a total neural network geek and you've played with PyTorch and TensorFlow a little bit now, gone through several tutorials and maybe built some custom models.  But you haven't set up your environment to include a GPU or two.  Or perhaps you haven't performed image augmentation for data sets in PyTorch?  Don't worry, by Level 3 you should be almost there and hopefully hungry for more machine learning experience.

Here, you'll get exposed to several types, qualities and sizes of datasets.  You'll also use many key Python libraries and general Data Science tools.  These paths can be walked separately or as one big, ML onboarding.  They are intended to help you get up and running for ML partner work quickly and thoroughly.

That being said, feedback is always welcome especially at this early stage.  Please enjoy responsibly.

### Tools and Technologies

Included are:

* Jupyter
* CustomVision.ai
* Scikit-learn
* PyTorch
* TensorFlow
* VMs and/or Docker

### Data

| Dataset | Description | Link |
|:------|:------|:------|
| Fashion MNIST Dataset (Source: Kaggle) | The Fashion MNIST dataset is a good one to move on to from the hand-written digits one.  It has 60,000 28x28 training images and 10,000 test images as csv files. | [Link](https://www.kaggle.com/zalando-research/fashionmnist/data) |
| Fruit Dataset (FIDS30) | The fruit image data set consists of 971 images of common fruit. The images are classified into 30 different fruit classes. | [Link](http://www.vicos.si/Downloads/FIDS30) |
| CIFAR-10 (Source: Kaggle) | The CIFAR-10 data consists of 60,000 32x32 color images in 10 classes, with 6000 images per class. There are 50,000 training images and 10,000 test images in this official data. | [Link](https://www.kaggle.com/c/cifar-10/data) |
| CIFAR-10 (Source: Toronto) | Same as above | [Link](http://www.cs.toronto.edu/~kriz/cifar.html) |

