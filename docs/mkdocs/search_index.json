{
    "docs": [
        {
            "location": "/",
            "text": "navigating-ml\n\n\nDo you feel like there's just too much to be aware of in the Deep Learning space today?  Concepts like Convolutional Neural Networks, GANs, Neural Style Transfer...and networks like AlexNet, ResNet, or Inception...frameworks like CNTK, TensorFlow, Caffe2, PyTorch...extra layers on top of those like TFLearn, Keras, Gluon, MMLSpark...\n\n\nIt can really seem overwhelming.  I propose we step back, take a nice, deep breath, and make a decision.  Are you a beginner in this field?  Are you on your way to really grokking neural nets, but still missing some key concepts?  Or are you as seasoned pro conceptually, but not super familiar with frameworks like CNTK (Microsoft's Cognitive Toolkit) or TensorFlow (Google's deep learning framework) or want to know more about the hardware and current tools for this kind of work?\n\n\nIf you suspect you are a beginner in this field, do you need some Python knowledge and fast?  If so go to the Getting Started section to load up on resources and once you're comfortable with data manipulation move on to the Level 1 Challenge for Dealing with Images to start building up your machine learning and neural network cred.\n\n\nDo you grok the basics of ML and perhaps what a fully-connected neural network is?  Have you had some exposure to TensorFlow or CNTK, but don't yet have deep working knowledge of Convolutional Neural Networks?  In that case, try jumping into the Level 2 section of Dealing with Images.  If it seems a little overwhelming, head back to the Level 1 area.  If it's not challenging enough, move on to the Level 3 section.\n\n\nMaybe you're a total neural network geek and you've played with CNTK and TensorFlow a little bit now, gone through several tutorials and maybe built some custom models.  But you haven't set up your environment to include a GPU or two.  Or perhaps you haven't performed image augmentation for input readers in CNTK or created a live REST endpoint and app to call your model?  These are tasks you'll likely encounter once you start working with partners and customers for building custom ML models.  They will want something deployed.  But don't worry, by Level 3 you should be almost there and hopefully hungry for more machine learning knowledge.\n\n\n\n\nTip:  Focus on the pipeline first and iterate on the model after.\n\n\n\n\nHere, you'll get exposed to several types, qualities and sizes of datasets.  You'll also use many key Python libraries and general Data Science tools.  These paths can be walked separately or as one big, ML onboarding.  They are intended to help you get up and running for ML partner work quickly and thoroughly.\n\n\nThat being said, feedback is always welcome especially at this early stage.  Please enjoy responsibly.\n\n\nQuick Reference\n\n\nTemplates\n\n\nTDB\n\n\nTools and Technologies\n\n\nIncluded are:\n\n\n\n\nJupyter\n\n\nCustomVision.ai\n\n\nScikit-learn\n\n\nCNTK\n\n\nTensorFlow\n\n\nAzure ML Workbench\n\n\nDeep Learning Virtual Machine\n\n\n\n\nData\n\n\n\n\n\n\n\n\nDataset\n\n\nDescription\n\n\nLink\n\n\n\n\n\n\n\n\n\n\nFashion MNIST Dataset (Source: Kaggle)\n\n\nThe Fashion MNIST dataset is a good one to move on to from the hand-written digits one.  It has 60,000 28x28 training images and 10,000 test images as csv files.\n\n\nLink\n\n\n\n\n\n\nFruit Dataset (FIDS30)\n\n\nThe fruit image data set consists of 971 images of common fruit. The images are classified into 30 different fruit classes.\n\n\nLink\n\n\n\n\n\n\nCIFAR-10 (Source: Kaggle)\n\n\nThe CIFAR-10 data consists of 60,000 32x32 color images in 10 classes, with 6000 images per class. There are 50,000 training images and 10,000 test images in this official data.\n\n\nLink\n\n\n\n\n\n\nCIFAR-10 (Source: Toronto)\n\n\nSame as above\n\n\nLink",
            "title": "Main"
        },
        {
            "location": "/#navigating-ml",
            "text": "Do you feel like there's just too much to be aware of in the Deep Learning space today?  Concepts like Convolutional Neural Networks, GANs, Neural Style Transfer...and networks like AlexNet, ResNet, or Inception...frameworks like CNTK, TensorFlow, Caffe2, PyTorch...extra layers on top of those like TFLearn, Keras, Gluon, MMLSpark...  It can really seem overwhelming.  I propose we step back, take a nice, deep breath, and make a decision.  Are you a beginner in this field?  Are you on your way to really grokking neural nets, but still missing some key concepts?  Or are you as seasoned pro conceptually, but not super familiar with frameworks like CNTK (Microsoft's Cognitive Toolkit) or TensorFlow (Google's deep learning framework) or want to know more about the hardware and current tools for this kind of work?  If you suspect you are a beginner in this field, do you need some Python knowledge and fast?  If so go to the Getting Started section to load up on resources and once you're comfortable with data manipulation move on to the Level 1 Challenge for Dealing with Images to start building up your machine learning and neural network cred.  Do you grok the basics of ML and perhaps what a fully-connected neural network is?  Have you had some exposure to TensorFlow or CNTK, but don't yet have deep working knowledge of Convolutional Neural Networks?  In that case, try jumping into the Level 2 section of Dealing with Images.  If it seems a little overwhelming, head back to the Level 1 area.  If it's not challenging enough, move on to the Level 3 section.  Maybe you're a total neural network geek and you've played with CNTK and TensorFlow a little bit now, gone through several tutorials and maybe built some custom models.  But you haven't set up your environment to include a GPU or two.  Or perhaps you haven't performed image augmentation for input readers in CNTK or created a live REST endpoint and app to call your model?  These are tasks you'll likely encounter once you start working with partners and customers for building custom ML models.  They will want something deployed.  But don't worry, by Level 3 you should be almost there and hopefully hungry for more machine learning knowledge.   Tip:  Focus on the pipeline first and iterate on the model after.   Here, you'll get exposed to several types, qualities and sizes of datasets.  You'll also use many key Python libraries and general Data Science tools.  These paths can be walked separately or as one big, ML onboarding.  They are intended to help you get up and running for ML partner work quickly and thoroughly.  That being said, feedback is always welcome especially at this early stage.  Please enjoy responsibly.",
            "title": "navigating-ml"
        },
        {
            "location": "/#quick-reference",
            "text": "",
            "title": "Quick Reference"
        },
        {
            "location": "/#templates",
            "text": "TDB",
            "title": "Templates"
        },
        {
            "location": "/#tools-and-technologies",
            "text": "Included are:   Jupyter  CustomVision.ai  Scikit-learn  CNTK  TensorFlow  Azure ML Workbench  Deep Learning Virtual Machine",
            "title": "Tools and Technologies"
        },
        {
            "location": "/#data",
            "text": "Dataset  Description  Link      Fashion MNIST Dataset (Source: Kaggle)  The Fashion MNIST dataset is a good one to move on to from the hand-written digits one.  It has 60,000 28x28 training images and 10,000 test images as csv files.  Link    Fruit Dataset (FIDS30)  The fruit image data set consists of 971 images of common fruit. The images are classified into 30 different fruit classes.  Link    CIFAR-10 (Source: Kaggle)  The CIFAR-10 data consists of 60,000 32x32 color images in 10 classes, with 6000 images per class. There are 50,000 training images and 10,000 test images in this official data.  Link    CIFAR-10 (Source: Toronto)  Same as above  Link",
            "title": "Data"
        },
        {
            "location": "/python/",
            "text": "Prerequisites\n\n\n\n\nPython (Rocks!)\n\n\n\n\n(2. Algebra, calculus and some basic ML knowledge won't hurt ya)\n\n\nPython\n\n\nJust Starting Out\n\n\nYour first Python course\n\n\nIntro to Python for Data Science from DataCamp\n (Time:  ~4 hours)\n\n\n\n\nPython basics\n\n\nLists\n\n\nFunctions and packages\n\n\nNumpy\n\n\n\n\nLearn about Jupyter\n\n\nNice, short video tour of Jupyter Notebooks\n\n\n\n\nGo to \nAzure Notebooks\n to check out Jupyter notebooks live and try to follow along with the video.\n\n\n\n\nIntermediate\n\n\nPython intro and data sciencey tools - go through in order or skip around\n\n\nPython for Data Science and Intro to Jupyter Notebooks and on Jupyter Notebooks on Azure\n - Note, solutions to exercises are in the last notebook. (Time: ~15 hours)\n\n\n\n\nBasics\n\n\nData Structures\n\n\nFunctional Programming\n\n\nSorting and Pattern Matching\n\n\nObject Oriented Programming\n\n\nBasic Difference from 2 to 3\n\n\nNumerical Computing\n\n\nData Analysis with pandas I\n\n\nData Analysis with pandas II\n\n\nMachine Learning I - ML Basics and Data Exploration\n\n\nMachine Learning II - Supervised and Unsupervised Learning\n\n\nMachine Learning III - Parameter Tuning and Model Evaluation\n\n\nVisualization\n\n\n\n\nA different take on Python and data science (either of these should cover your Python needs)\n\n\nFor a more in-depth Python course, this is a good one on edX out of UC San Diego:  \nPython for Data Science from edX\n.  (Time:  10 weeks/8-10 hours per week)\n\n\n\n\nBasic process of data science\n\n\nPython and Jupyter notebooks\n\n\nAn applied understanding of how to manipulate and analyze uncurated datasets\n\n\nBasic statistical analysis and machine learning methods\n\n\nHow to effectively visualize results\n\n\n\n\nAdvanced\n\n\nSome books really worth checking out\n\n\nFor a great dive into Python in the context of ML check out this book by Sebastian Raschka (you'll get to write algorithms from scratch in pure Python!): \nPython Machine Learning (2nd Ed.)\n\n\nNot sure if this book is out yet, but Sebastian Raschka is writing a sequel with more deep learning in Python with TensorFlow: \nIntroduction to Artificial Neural Networks and Deep Learning\n.\n\n\n\"This book is concerned with the nuts and bolts of manipulating, processing, cleaning, and crunching data in Python. My goal is to offer a guide to the parts of the Python programming language and its data-oriented library ecosystem and tools that will equip you to become an effective data analyst. While 'data analysis' is in the title of the book, the focus is specifically on Python programming, libraries, and tools as opposed to data analysis methodology. This is the Python programming you need for data analysis.\"  \nPython for Data Analysis: Data Wrangling with Pandas, NumPy, and IPython by Wes McKinney\n\n\n\"Perhaps you would like to give your homemade robot a brain of its own? Make it recognize faces? Or learn to walk around? Or maybe your company has tons of data (user logs, financial data, production data, machine sensor data, hotline stats, HR reports, etc.), and more than likely you could unearth some hidden gems if you just knew where to look.\" \nHands-On Machine Learning with Scikit-Learn and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems by Aur\u00e9lien G\u00e9ron",
            "title": "Python"
        },
        {
            "location": "/python/#prerequisites",
            "text": "Python (Rocks!)   (2. Algebra, calculus and some basic ML knowledge won't hurt ya)",
            "title": "Prerequisites"
        },
        {
            "location": "/python/#python",
            "text": "",
            "title": "Python"
        },
        {
            "location": "/python/#just-starting-out",
            "text": "Your first Python course  Intro to Python for Data Science from DataCamp  (Time:  ~4 hours)   Python basics  Lists  Functions and packages  Numpy   Learn about Jupyter  Nice, short video tour of Jupyter Notebooks   Go to  Azure Notebooks  to check out Jupyter notebooks live and try to follow along with the video.",
            "title": "Just Starting Out"
        },
        {
            "location": "/python/#intermediate",
            "text": "Python intro and data sciencey tools - go through in order or skip around  Python for Data Science and Intro to Jupyter Notebooks and on Jupyter Notebooks on Azure  - Note, solutions to exercises are in the last notebook. (Time: ~15 hours)   Basics  Data Structures  Functional Programming  Sorting and Pattern Matching  Object Oriented Programming  Basic Difference from 2 to 3  Numerical Computing  Data Analysis with pandas I  Data Analysis with pandas II  Machine Learning I - ML Basics and Data Exploration  Machine Learning II - Supervised and Unsupervised Learning  Machine Learning III - Parameter Tuning and Model Evaluation  Visualization   A different take on Python and data science (either of these should cover your Python needs)  For a more in-depth Python course, this is a good one on edX out of UC San Diego:   Python for Data Science from edX .  (Time:  10 weeks/8-10 hours per week)   Basic process of data science  Python and Jupyter notebooks  An applied understanding of how to manipulate and analyze uncurated datasets  Basic statistical analysis and machine learning methods  How to effectively visualize results",
            "title": "Intermediate"
        },
        {
            "location": "/python/#advanced",
            "text": "Some books really worth checking out  For a great dive into Python in the context of ML check out this book by Sebastian Raschka (you'll get to write algorithms from scratch in pure Python!):  Python Machine Learning (2nd Ed.)  Not sure if this book is out yet, but Sebastian Raschka is writing a sequel with more deep learning in Python with TensorFlow:  Introduction to Artificial Neural Networks and Deep Learning .  \"This book is concerned with the nuts and bolts of manipulating, processing, cleaning, and crunching data in Python. My goal is to offer a guide to the parts of the Python programming language and its data-oriented library ecosystem and tools that will equip you to become an effective data analyst. While 'data analysis' is in the title of the book, the focus is specifically on Python programming, libraries, and tools as opposed to data analysis methodology. This is the Python programming you need for data analysis.\"   Python for Data Analysis: Data Wrangling with Pandas, NumPy, and IPython by Wes McKinney  \"Perhaps you would like to give your homemade robot a brain of its own? Make it recognize faces? Or learn to walk around? Or maybe your company has tons of data (user logs, financial data, production data, machine sensor data, hotline stats, HR reports, etc.), and more than likely you could unearth some hidden gems if you just knew where to look.\"  Hands-On Machine Learning with Scikit-Learn and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems by Aur\u00e9lien G\u00e9ron",
            "title": "Advanced"
        },
        {
            "location": "/level1/level1_setup/",
            "text": "Hardware and Software\n\n\nFor the first part of the Beginner Challenge, you'll only need \nAzure Notebooks\n as an online resource.\n\n\nFor the Transfer Learning and TensorFlow parts you'll need:\n\n\n\n\n(Deploy when ready) \nLinux (Ubuntu) Deep Learning Virtual Machine\n Standard NC6\n\n\n\n\n\n\nTip: place everything for this set of challenges in the same resource group to tear down together at the end.  Also, stop pricey VMs when you\u2019re no longer using them.\n\n\n\n\nFor the Workbench parts you'll need some items locally (note:  Workbench is available for Windows or macOS so this is a good chance to build up some Data Science tools locally - nice when you have spotty wifi):\n\n\n\n\nDocker for Mac or Docker for Windows (avoid Toolbox)\n\n\nInstall \nAzure ML Workbench\n\n\n\n\n\n\nPlan to work with CNTK locally?  Make sure you check out which versions of Python it works with and note it's for Windows and Ubuntu-flavored Linux as of now.  If you are on a different OS there's a Docker image that is easy to set up and begin right away with CNTK.\n\n\n\n\n\n\nCNTK Install - \nDocs\n\n\n\n\n\n\nTensorFlow can be found on all Linux and Windows Data Science Virtual Machines and Deep Learning Virtual Machines along with a long list of common data science tools - see \nDocs\n\n\n\n\nGood Idea:\n\n\n\n\nStackOverflow account\n\n\n\n\nAdditional Resources\n\n\n\n\nThe Stats/ML StackExchange is a useful place to pose questions \nLink",
            "title": "Setup"
        },
        {
            "location": "/level1/level1_setup/#hardware-and-software",
            "text": "For the first part of the Beginner Challenge, you'll only need  Azure Notebooks  as an online resource.  For the Transfer Learning and TensorFlow parts you'll need:   (Deploy when ready)  Linux (Ubuntu) Deep Learning Virtual Machine  Standard NC6    Tip: place everything for this set of challenges in the same resource group to tear down together at the end.  Also, stop pricey VMs when you\u2019re no longer using them.   For the Workbench parts you'll need some items locally (note:  Workbench is available for Windows or macOS so this is a good chance to build up some Data Science tools locally - nice when you have spotty wifi):   Docker for Mac or Docker for Windows (avoid Toolbox)  Install  Azure ML Workbench    Plan to work with CNTK locally?  Make sure you check out which versions of Python it works with and note it's for Windows and Ubuntu-flavored Linux as of now.  If you are on a different OS there's a Docker image that is easy to set up and begin right away with CNTK.    CNTK Install -  Docs    TensorFlow can be found on all Linux and Windows Data Science Virtual Machines and Deep Learning Virtual Machines along with a long list of common data science tools - see  Docs   Good Idea:   StackOverflow account",
            "title": "Hardware and Software"
        },
        {
            "location": "/level1/level1_setup/#additional-resources",
            "text": "The Stats/ML StackExchange is a useful place to pose questions  Link",
            "title": "Additional Resources"
        },
        {
            "location": "/level1/level1_prep/",
            "text": "Level 1 Preparation\n\n\nTo begin at this level you should have:\n\n\n\n\nFamiliarity with Python for general purpose programming\n\n\nWorking knowledge of traditional ML\n\n\nBasic data mining skills\n\n\n\n\n...\n\n\nConcepts\n\n\nNeural Networks\n\n\nRead through \nthis\n excellent explanation of a single-layer neural network.  This information will lay the foundation for these sets of challenges and help you get started from the ground-up, quickly with key concepts and Python code snippets.\n\n\nDealing with Image Data\n\n\n\n\nManipulation/conversions \nNeed doc\n\n\nScaling \nNeed doc\n\n\nTransforms/augmentation \nNeed doc\n\n\n\n\n...\n\n\nTools\n\n\n\n\nGit and GitHub for version control. \nNeed doc\n\n\nJupyter notebook skills. \nChapter 1 Python Data Science Handbook\n\n\nGet a good grasp of Python for data tasks:\n\n\nHow to read data (matplotlib, Pillow/PIL, opencv)\n\n\nHow to manipulate data (numpy, pandas, scikit-learn) \n\n\nHow to plot data (matplotlib, plotly)\n\n\nTraditional ML (scikit-learn)\n\n\n\n\n\n\n\n\n...\n\n\nA Learning Path is under dev to cover the above topics in linear fashion\n\n\nAdditional Resources\n\n\nScikit-Learn\n\n\nExcellent 3-hr scikit-learn tutorials from PyCon 2015:\n\n\n\n\nWatch \nthis\n scikit-learn tutorial by Jake VanderPlas (Part 1) and \nthe next\n tutorial by Olivier Grisel (Part 2).\n\n\n\n\nLearn about ML and Python scikit-learn in this \nvideo series",
            "title": "Preparation"
        },
        {
            "location": "/level1/level1_prep/#level-1-preparation",
            "text": "To begin at this level you should have:   Familiarity with Python for general purpose programming  Working knowledge of traditional ML  Basic data mining skills   ...",
            "title": "Level 1 Preparation"
        },
        {
            "location": "/level1/level1_prep/#concepts",
            "text": "",
            "title": "Concepts"
        },
        {
            "location": "/level1/level1_prep/#neural-networks",
            "text": "Read through  this  excellent explanation of a single-layer neural network.  This information will lay the foundation for these sets of challenges and help you get started from the ground-up, quickly with key concepts and Python code snippets.",
            "title": "Neural Networks"
        },
        {
            "location": "/level1/level1_prep/#dealing-with-image-data",
            "text": "Manipulation/conversions  Need doc  Scaling  Need doc  Transforms/augmentation  Need doc   ...",
            "title": "Dealing with Image Data"
        },
        {
            "location": "/level1/level1_prep/#tools",
            "text": "Git and GitHub for version control.  Need doc  Jupyter notebook skills.  Chapter 1 Python Data Science Handbook  Get a good grasp of Python for data tasks:  How to read data (matplotlib, Pillow/PIL, opencv)  How to manipulate data (numpy, pandas, scikit-learn)   How to plot data (matplotlib, plotly)  Traditional ML (scikit-learn)     ...  A Learning Path is under dev to cover the above topics in linear fashion",
            "title": "Tools"
        },
        {
            "location": "/level1/level1_prep/#additional-resources",
            "text": "",
            "title": "Additional Resources"
        },
        {
            "location": "/level1/level1_prep/#scikit-learn",
            "text": "Excellent 3-hr scikit-learn tutorials from PyCon 2015:   Watch  this  scikit-learn tutorial by Jake VanderPlas (Part 1) and  the next  tutorial by Olivier Grisel (Part 2).   Learn about ML and Python scikit-learn in this  video series",
            "title": "Scikit-Learn"
        },
        {
            "location": "/level1/level1_practice/",
            "text": "Level 1 Challenge\n\n\nIn this Beginner Challenge you'll learn about basic ML and neural networks hands-on with Jupyter notebooks and Python.  You'll be introduced to scikit-learn, CNTK, and TensorFlow as Python packages and the Azure ML Workbench tool.  Here and throughout these challenges you'll work with these image datasets: the fruit FIDS30 dataset, the Kaggle Fashion MNIST dataset and the CIFAR-10 (tiny images) dataset.\n\n\nCustom Vision\n\n\n\n\nDownload the \nfruit dataset\n and build a fruit image classifier with \nhttps://customvision.ai/\n.\n\n\n\n\nFirst Custom ML\n\n\nImage Classification\n\n\nCreate a Python program to classify images from Fashion MNIST Dataset (get \nhere\n) leveraging code samples from the Python Data Science Handbook - \nRef\n.  Do this in a Jupyter notebook (any service or locally) - recall you learned about this tool the Getting Started and Level 1 Preparation sections.  It might help to examine the existing data format for \nsklearn.datasets.load_digits\n so that you can convert into that format to utilize the algorithms in \nsklearn\n (scikit-learn).  Refer to Chapter 2 and 3 of this Handbook for information on data manipulation in Python if not already familiar.\n\n\nObject Detection\n\n\nCreate a Python program to detect cats in 2D images by leveraging code samples from the Python Data Science Handbook - \nRef\n.  Do this in a Jupyter notebook (any service or locally) - recall you learned about this tool the Getting Started and Level 1 Preparation sections.  It might help to examine the existing data format for \nsklearn.datasets.fetch_lfw_people\n so that you can convert into that format to utilize the algorithms in \nsklearn\n (scikit-learn) to create this detector.  Refer to Chapter 2 and 3 of this Handbook for information on data manipulation in Python if not already familiar.\n\n\nBasic Neural Nets\n\n\nThe purpose of the Basic Neural Nets exercises are to familiarize you with how a simple neuron works and then set of a few neurons - all from the ground-up - this knowledge will serve you well.  It will really get to the core of neural nets and give you a perfect \"from scratch\" introduction (the code template already exists around the infamous iris dataset, you'll just make it work with some fashionable images).  If we want to get to know deep neural nets, why not dive in deep to start!\n\n\n\n\nUse \nAzure Notebooks\n for this tutorial.  Fire up a blank Python 3.5 Jupyter notebook for this.\n\n\nGet the following sample image dataset loaded in your Jupyter notebook: \ntrain and test Fashion MNIST Dataset (Source: Kaggle)\n\n\nAdapt a from-scratch Perceptron as in this \nJupyter notebook\n to train and test on the image dataset.\n\n\nUse the URL option when opening up a new notebook in Azure Notebooks\n\n\nOr, download by right clicking on \"Raw\" and \"Save link as...\"\n\n\nRe-implement the Perceptron with \nsklearn\n (scikit-learn)\n\n\n\n\n\n\nAdapt a from-scratch Multilayer Perceptron (MLP) as in this \nJupyter notebook\n\n\nUse the URL option when opening up a new notebook in Azure Notebooks\n\n\nOr, download by right clicking on \"Raw\" and \"Save link as...\"\n\n\nRe-implement the MLP with \nsklearn\n\n\n\n\n\n\n\n\nRunning and Testing Locally with Azure ML Workbench\n\n\nNow that you've got a couple of implementations of a Multilayer Perceptron, go ahead and setup an experiment in Azure ML Workbench, a nice new public preview Data Science workbench, to train and test on the Fashion dataset above.\n\n\nUse the iris dataset template and tutorial as an example - see the \nDocs\n.\n\n\n\n\nRead your csv train file into Azure ML Workbench\n\n\nModify the iris template to train a model with any of the above classification algorithms locally in docker\n\n\nTest with the \nscore.py\n file locally in docker\n\n\nCheck run history for metrics (observe the use of scikit-learn's confusion matrix, etc.)\n\n\nContainerize\n\n\nDeploy this to a Kubernetes cluster\n\n\nTest the endpoint in any script or application that you want to build (in any language)\n\n\n\n\nTransfer Learning on the Deep Learning Virtual Machine with CNTK\n\n\nNow, we are going to totally switch gears and tools.  We'll spin up a Deep Learning Virtual Machine and leverage raw Python scripts already kindly prepared for us on a classic image dataset, CIFAR-10, which has ten classes.  Here, for ease of use and speed we'll use Transfer Learning as well.\n\n\n\n\nConnect to your Linux Deep Learning Virtual Machine (DLVM) in Azure with x2go (see instructions in \nDocs\n).\n\n\nUse ResNet to train a CIFAR 10 classifier\n\n\nGo ahead and clone the \nCNTK GitHub repo\n.\n\n\nGet the data by running the \ninstall_cifar10.py\n in the \nCNTK/Examples/Image/DataSets/CIFAR-10/\n folder of the \nCNTK GitHub repo\n - it's suggested to copy this folder out to some other place to keep your CNTK repo download clean.  \nNote\n: this download may take 10-20 minutes - it's a lot of data and data conversions.\n\n\nRun \nthis\n script on the command line on your DLVM, to train your classifier with Transfer Learning (the base model here is \nResNet\n).\n\n\n\n\n\n\n\n\nTaste of TensorFlow\n\n\nThis will serve as a gentle intro to TensorFlow.  Here, you'll take advantage of the Inception-v3 model pre-trained on the ImageNet dataset and simply classify a new image using the pre-built script.\n\n\nGo through up to and including \"Usage with Python API\" such that you can classify your own jpeg (note, there are 1000 classes in this Inception-v3 model):  \nTutorial\n using your Linux DLVM.\n\n\n\n\n\"Git clone\" the indicated repository\n\n\nRun the script on the command line on your DLVM\n\n\nRun the script with your own jpeg\n\n\nTake a peek at the code to see how the model was built\n\n\n\n\nAdditional Help\n\n\n\n\nStackOverflow with \nsklearn\n, \ncntk\n or \ntensorflow\n as tag\n\n\nIssues on CNTK GitHub repo",
            "title": "Practice"
        },
        {
            "location": "/level1/level1_practice/#level-1-challenge",
            "text": "In this Beginner Challenge you'll learn about basic ML and neural networks hands-on with Jupyter notebooks and Python.  You'll be introduced to scikit-learn, CNTK, and TensorFlow as Python packages and the Azure ML Workbench tool.  Here and throughout these challenges you'll work with these image datasets: the fruit FIDS30 dataset, the Kaggle Fashion MNIST dataset and the CIFAR-10 (tiny images) dataset.",
            "title": "Level 1 Challenge"
        },
        {
            "location": "/level1/level1_practice/#custom-vision",
            "text": "Download the  fruit dataset  and build a fruit image classifier with  https://customvision.ai/ .",
            "title": "Custom Vision"
        },
        {
            "location": "/level1/level1_practice/#first-custom-ml",
            "text": "",
            "title": "First Custom ML"
        },
        {
            "location": "/level1/level1_practice/#image-classification",
            "text": "Create a Python program to classify images from Fashion MNIST Dataset (get  here ) leveraging code samples from the Python Data Science Handbook -  Ref .  Do this in a Jupyter notebook (any service or locally) - recall you learned about this tool the Getting Started and Level 1 Preparation sections.  It might help to examine the existing data format for  sklearn.datasets.load_digits  so that you can convert into that format to utilize the algorithms in  sklearn  (scikit-learn).  Refer to Chapter 2 and 3 of this Handbook for information on data manipulation in Python if not already familiar.",
            "title": "Image Classification"
        },
        {
            "location": "/level1/level1_practice/#object-detection",
            "text": "Create a Python program to detect cats in 2D images by leveraging code samples from the Python Data Science Handbook -  Ref .  Do this in a Jupyter notebook (any service or locally) - recall you learned about this tool the Getting Started and Level 1 Preparation sections.  It might help to examine the existing data format for  sklearn.datasets.fetch_lfw_people  so that you can convert into that format to utilize the algorithms in  sklearn  (scikit-learn) to create this detector.  Refer to Chapter 2 and 3 of this Handbook for information on data manipulation in Python if not already familiar.",
            "title": "Object Detection"
        },
        {
            "location": "/level1/level1_practice/#basic-neural-nets",
            "text": "The purpose of the Basic Neural Nets exercises are to familiarize you with how a simple neuron works and then set of a few neurons - all from the ground-up - this knowledge will serve you well.  It will really get to the core of neural nets and give you a perfect \"from scratch\" introduction (the code template already exists around the infamous iris dataset, you'll just make it work with some fashionable images).  If we want to get to know deep neural nets, why not dive in deep to start!   Use  Azure Notebooks  for this tutorial.  Fire up a blank Python 3.5 Jupyter notebook for this.  Get the following sample image dataset loaded in your Jupyter notebook:  train and test Fashion MNIST Dataset (Source: Kaggle)  Adapt a from-scratch Perceptron as in this  Jupyter notebook  to train and test on the image dataset.  Use the URL option when opening up a new notebook in Azure Notebooks  Or, download by right clicking on \"Raw\" and \"Save link as...\"  Re-implement the Perceptron with  sklearn  (scikit-learn)    Adapt a from-scratch Multilayer Perceptron (MLP) as in this  Jupyter notebook  Use the URL option when opening up a new notebook in Azure Notebooks  Or, download by right clicking on \"Raw\" and \"Save link as...\"  Re-implement the MLP with  sklearn",
            "title": "Basic Neural Nets"
        },
        {
            "location": "/level1/level1_practice/#running-and-testing-locally-with-azure-ml-workbench",
            "text": "Now that you've got a couple of implementations of a Multilayer Perceptron, go ahead and setup an experiment in Azure ML Workbench, a nice new public preview Data Science workbench, to train and test on the Fashion dataset above.  Use the iris dataset template and tutorial as an example - see the  Docs .   Read your csv train file into Azure ML Workbench  Modify the iris template to train a model with any of the above classification algorithms locally in docker  Test with the  score.py  file locally in docker  Check run history for metrics (observe the use of scikit-learn's confusion matrix, etc.)  Containerize  Deploy this to a Kubernetes cluster  Test the endpoint in any script or application that you want to build (in any language)",
            "title": "Running and Testing Locally with Azure ML Workbench"
        },
        {
            "location": "/level1/level1_practice/#transfer-learning-on-the-deep-learning-virtual-machine-with-cntk",
            "text": "Now, we are going to totally switch gears and tools.  We'll spin up a Deep Learning Virtual Machine and leverage raw Python scripts already kindly prepared for us on a classic image dataset, CIFAR-10, which has ten classes.  Here, for ease of use and speed we'll use Transfer Learning as well.   Connect to your Linux Deep Learning Virtual Machine (DLVM) in Azure with x2go (see instructions in  Docs ).  Use ResNet to train a CIFAR 10 classifier  Go ahead and clone the  CNTK GitHub repo .  Get the data by running the  install_cifar10.py  in the  CNTK/Examples/Image/DataSets/CIFAR-10/  folder of the  CNTK GitHub repo  - it's suggested to copy this folder out to some other place to keep your CNTK repo download clean.   Note : this download may take 10-20 minutes - it's a lot of data and data conversions.  Run  this  script on the command line on your DLVM, to train your classifier with Transfer Learning (the base model here is  ResNet ).",
            "title": "Transfer Learning on the Deep Learning Virtual Machine with CNTK"
        },
        {
            "location": "/level1/level1_practice/#taste-of-tensorflow",
            "text": "This will serve as a gentle intro to TensorFlow.  Here, you'll take advantage of the Inception-v3 model pre-trained on the ImageNet dataset and simply classify a new image using the pre-built script.  Go through up to and including \"Usage with Python API\" such that you can classify your own jpeg (note, there are 1000 classes in this Inception-v3 model):   Tutorial  using your Linux DLVM.   \"Git clone\" the indicated repository  Run the script on the command line on your DLVM  Run the script with your own jpeg  Take a peek at the code to see how the model was built",
            "title": "Taste of TensorFlow"
        },
        {
            "location": "/level1/level1_practice/#additional-help",
            "text": "StackOverflow with  sklearn ,  cntk  or  tensorflow  as tag  Issues on CNTK GitHub repo",
            "title": "Additional Help"
        },
        {
            "location": "/level2/level2_setup/",
            "text": "Setup\n\n\n\n\n\n\n(Deploy when ready if you don't have it yet) \nLinux (Ubuntu) Deep Learning Virtual Machine\n Standard NC6\n\n\n\n\nTip: place everything for this set of challenges in the same resource group to tear down together at the end.\n\n\n\n\n\n\n\n\nEnsure Jupyter notebooks are working.\n\n\n\n\n\"access the Jupyter notebook server from any host. Just navigate in the browser to \nhttps://<VM DNS name or IP Address>:8000/\n\" (\nref\n - check out \"Jupyter notebook\" for more)",
            "title": "Setup"
        },
        {
            "location": "/level2/level2_setup/#setup",
            "text": "(Deploy when ready if you don't have it yet)  Linux (Ubuntu) Deep Learning Virtual Machine  Standard NC6   Tip: place everything for this set of challenges in the same resource group to tear down together at the end.     Ensure Jupyter notebooks are working.   \"access the Jupyter notebook server from any host. Just navigate in the browser to  https://<VM DNS name or IP Address>:8000/ \" ( ref  - check out \"Jupyter notebook\" for more)",
            "title": "Setup"
        },
        {
            "location": "/level2/level2_prep/",
            "text": "Level 2 Preparation\n\n\nNow it's time to really learn about CNTK and classifiers such as logistic regression, multilayer perceptron, and convolutional network (CNN/ConvNet) classifiers.  The MNIST hand-written digits dataset is used in the following course to classify grey-scale images of digits.  We'll use this code in our Challenge section so go ahead and get familiar with it now by taking this course.\n\n\nWork through the first four modules of the free Deep Learning Explained edX \ncourse\n.  Each module should take 1-2 hours each.\n\n\n\n\nLearn concepts around neural networks for image applications.\n\n\nList the differences between a Convolutional (ConvNet/CNN) and regular Dense Neural Network.\n\n\nList and give examples of the tunable hyperparameters one can find in a ConvNet.\n...\n\n\n\n\n\n\n\n\nFor Quick Reference - MNIST Digits and CNTK Notebooks and Videos\n\n\nBelow are links to some of the Jupyter notebooks used in the edX Deep Learning Explained course (linked to above) using the MNIST hand-written digits dataset.  Included are links to accompanying videos by Microsoft data scientists around this example.\n\n\nThey are meant to be worked on in order, each tutorial building on the previous.  Ideally, you will have also watched the accompanying lectures from the course.\n\n\n\n\n\n\n\n\nTopic\n\n\nTutorial on Jupyter\n\n\nVideo Link\n\n\n\n\n\n\n\n\n\n\nLoading MNIST data\n\n\nNotebook 103A on CNTK GitHub\n\n\nVideo\n\n\n\n\n\n\nReading MNIST data in CNTK\n\n\nNotebook 103B on CNTK GitHub\n\n\nVideo\n\n\n\n\n\n\nCreating and training a logistic regression classifier\n\n\nNotebook 103B on CNTK GitHub\n\n\nVideo\n\n\n\n\n\n\nPredicting on data\n\n\nNotebook 103B on CNTK GitHub\n\n\nVideo\n\n\n\n\n\n\nTraining and testing a Multilayer Perceptron\n\n\nNotebook 103C on CNTK GitHub\n\n\nVideo\n\n\n\n\n\n\nReading MNIST data in CNTK (CNN version)\n\n\nNotebook 103D on CNTK GitHub\n\n\nVideo\n\n\n\n\n\n\nUnderstanding CNN filters, strides and padding\n\n\nNotebook 103D on CNTK GitHub\n\n\nVideo\n\n\n\n\n\n\nBuild CNN model, understand layers and number of parameters\n\n\nNotebook 103D on CNTK GitHub\n\n\nVideo\n\n\n\n\n\n\nTraining and evaluating CNN model\n\n\nNotebook 103D on CNTK GitHub\n\n\nVideo\n\n\n\n\n\n\n\n\n\n\nUse these notebooks for free online:  \nCNTK Tutorials on Azure Notebooks",
            "title": "Preparation"
        },
        {
            "location": "/level2/level2_prep/#level-2-preparation",
            "text": "Now it's time to really learn about CNTK and classifiers such as logistic regression, multilayer perceptron, and convolutional network (CNN/ConvNet) classifiers.  The MNIST hand-written digits dataset is used in the following course to classify grey-scale images of digits.  We'll use this code in our Challenge section so go ahead and get familiar with it now by taking this course.  Work through the first four modules of the free Deep Learning Explained edX  course .  Each module should take 1-2 hours each.   Learn concepts around neural networks for image applications.  List the differences between a Convolutional (ConvNet/CNN) and regular Dense Neural Network.  List and give examples of the tunable hyperparameters one can find in a ConvNet.\n...",
            "title": "Level 2 Preparation"
        },
        {
            "location": "/level2/level2_prep/#for-quick-reference-mnist-digits-and-cntk-notebooks-and-videos",
            "text": "Below are links to some of the Jupyter notebooks used in the edX Deep Learning Explained course (linked to above) using the MNIST hand-written digits dataset.  Included are links to accompanying videos by Microsoft data scientists around this example.  They are meant to be worked on in order, each tutorial building on the previous.  Ideally, you will have also watched the accompanying lectures from the course.     Topic  Tutorial on Jupyter  Video Link      Loading MNIST data  Notebook 103A on CNTK GitHub  Video    Reading MNIST data in CNTK  Notebook 103B on CNTK GitHub  Video    Creating and training a logistic regression classifier  Notebook 103B on CNTK GitHub  Video    Predicting on data  Notebook 103B on CNTK GitHub  Video    Training and testing a Multilayer Perceptron  Notebook 103C on CNTK GitHub  Video    Reading MNIST data in CNTK (CNN version)  Notebook 103D on CNTK GitHub  Video    Understanding CNN filters, strides and padding  Notebook 103D on CNTK GitHub  Video    Build CNN model, understand layers and number of parameters  Notebook 103D on CNTK GitHub  Video    Training and evaluating CNN model  Notebook 103D on CNTK GitHub  Video      Use these notebooks for free online:   CNTK Tutorials on Azure Notebooks",
            "title": "For Quick Reference - MNIST Digits and CNTK Notebooks and Videos"
        },
        {
            "location": "/level2/level2_practice/",
            "text": "Level 2 Challenge\n\n\nIn this intermediate Challenge, you'll apply what you've learned in the edX Deep Learning Explained course, leveraging the Jupyter notebooks you became familiar with in the course.  You'll start exploring the CIFAR-10 dataset along with other datsets in CNTK and TensorFlow.\n\n\nAdapt Deep Learning Explained CNTK Notebooks\n\n\nHere you'll adapt the Jupyter notebooks from the edX course - using the DLVM as the notebook server.  If you have a GPU at home, you may go ahead and use it, just be sure to follow the install instructions for CNTK in the \nAdvanced section\n.\n\n\n\n\nLog into the Jupyter server on the DLVM - from any browser.\n\n\nTake the CNN Lab notebooks from edX course and use \nCIFAR 10 dataset in CNTK format\n instead to classify images into the 10 classes:  airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck instead of handwritten digits.\n\n\nIf you haven't cloned it yet, go ahead and clone the \nCNTK GitHub repo\n.\n\n\nGet the data by running the \ninstall_cifar10.py\n in the \nCNTK/Examples/Image/DataSets/CIFAR-10/\n folder of the \nCNTK GitHub repo\n - it's suggested to copy this folder out to some other place to keep your CNTK repo download clean.  \nNote\n: this download may take several minutes.\n...\n\n\n\n\n\n\nGo online and find 5 png's of cats and dogs.  Reshape them and pad them to be 32x32 pixels using Pillow (see ImageOps).  Convert them to the proper CNTK format.  Test the network with these, following the guidelines and lessons you learned in the edX course.  Now find an image of a coconut or lime and test the network with this.  What is wrong with using a food image?\n\n\nCreate a new label called \"food\" and add this \nfruit dataset\n, leaving some out of training for testing.  Try your coconut image again.  What if now you tested with a hot dog image?\n\n\n\n\nTaste of TensorFlow\n\n\n...\n\n\nWant More?\n\n\nCheck out Rodrigo Benenson's \nblog\n to find out the best algorithm for classifying with CIFAR-10 and implement it.  May the force be with you.",
            "title": "Practice"
        },
        {
            "location": "/level2/level2_practice/#level-2-challenge",
            "text": "In this intermediate Challenge, you'll apply what you've learned in the edX Deep Learning Explained course, leveraging the Jupyter notebooks you became familiar with in the course.  You'll start exploring the CIFAR-10 dataset along with other datsets in CNTK and TensorFlow.",
            "title": "Level 2 Challenge"
        },
        {
            "location": "/level2/level2_practice/#adapt-deep-learning-explained-cntk-notebooks",
            "text": "Here you'll adapt the Jupyter notebooks from the edX course - using the DLVM as the notebook server.  If you have a GPU at home, you may go ahead and use it, just be sure to follow the install instructions for CNTK in the  Advanced section .   Log into the Jupyter server on the DLVM - from any browser.  Take the CNN Lab notebooks from edX course and use  CIFAR 10 dataset in CNTK format  instead to classify images into the 10 classes:  airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck instead of handwritten digits.  If you haven't cloned it yet, go ahead and clone the  CNTK GitHub repo .  Get the data by running the  install_cifar10.py  in the  CNTK/Examples/Image/DataSets/CIFAR-10/  folder of the  CNTK GitHub repo  - it's suggested to copy this folder out to some other place to keep your CNTK repo download clean.   Note : this download may take several minutes.\n...    Go online and find 5 png's of cats and dogs.  Reshape them and pad them to be 32x32 pixels using Pillow (see ImageOps).  Convert them to the proper CNTK format.  Test the network with these, following the guidelines and lessons you learned in the edX course.  Now find an image of a coconut or lime and test the network with this.  What is wrong with using a food image?  Create a new label called \"food\" and add this  fruit dataset , leaving some out of training for testing.  Try your coconut image again.  What if now you tested with a hot dog image?",
            "title": "Adapt Deep Learning Explained CNTK Notebooks"
        },
        {
            "location": "/level2/level2_practice/#taste-of-tensorflow",
            "text": "...",
            "title": "Taste of TensorFlow"
        },
        {
            "location": "/level2/level2_practice/#want-more",
            "text": "Check out Rodrigo Benenson's  blog  to find out the best algorithm for classifying with CIFAR-10 and implement it.  May the force be with you.",
            "title": "Want More?"
        },
        {
            "location": "/level3/level3_setup/",
            "text": "Setup\n\n\nYou'll be doing most thing locally in this Advanced Challenge.\n\n\nGetting your Environment Set Up\n\n\nHardware\n\n\nThese are some highly rated suggestions.  You may of course try out the Practice section on a CPU machine.  There's a cloud option below as well.\n\n\nComputer-Laptop\n\n\nAnything with a NVIDIA GTX 1060 (GPU) is good if you travel a lot or cannot necessarily depend on wifi.\n\n\n\n\nE.g.:  https://www.razerzone.com/gaming-systems/razer-blade-pro - plan to get a 1060 w/ 256ssd + 2tb spinner\n\n\nGTX 1080 (extra $2k; only get if this is your primary machine and you travel a lot/have spotty wifi).\n\n\n\n\nComputer-Desktop\n\n\nAny gaming desktop with a min GTX 1080.\u00a0\n\n\n\n\nAlt 1: Custom built.\u00a0 If you go this route -> Add up your GPU ram, multiply by 2 for your min RAM.\u00a0 Get a CPU w/ 48 lanes (so you can go 2 GPUs later).\n\n\nAlt 2: \nhttps://lambdal.com/products/quad\n (this is probably over kill honestly, and your electricity bill might double.\u00a0 Will make a great space heater)\n\n\n\n\nComputer-Remote\n\n\nUse Azure and set up a jupyter notebook.\u00a0 This takes more learning and understanding but is the cheapest getting started option.\n\n\nIt's suggested to provision a new NC-6 (or NC12) DSVM on Ubuntu, updating everything, installing the packages, adding a 1TB data disk and kicking off a password protected Jupyter Notebook in a tmux session.\u00a0 DO NOT put sensitive data on this.\u00a0 It has open ports, admin rights to the system, is password protected only and it's not believed to use SSL unless you set up a certificate.\u00a0 There are other more secure options, though they are more advanced and not covered in this getting started.\n\n\nIoT-Test_Device\n\n\nRaspberry Pi v3, Nvidia TX-1 or Nvidia TX-2.\u00a0 If you are feeling adventurous get a few arduinos as well.\n\n\nSoftware\n\n\n\n\nDocker for Mac or Docker for Windows (avoid Toolbox)\n\n\nAnaconda\n\n\nIf you have a GPU\n\n\nGo to \nCuda Downloads\n\n\nJoin Nvidia Developer program\n\n\nUpdate your GPU drivers\n\n\nInstall Cuda & Cudnn\n\n\n\n\n\n\nInstall your packages\n\n\nOpen an admin cmd prompt\n\n\nPip install \nplotly\n (most other packages come with Anaconda)\n\n\nPip install the latest 3.6 GPU-1bit-SGD (if you got a GPU otherwise install CPU version)\n\n\nCNTK 2.2\n\n\nAs of today this is: \npip install https://cntk.ai/PythonWheel/GPU-1bit-SGD/cntk-2.2-cp36-cp36m-win_amd64.whl\n\n\n\n\n\n\n\n\n\n\nInstall \nAzure ML Workbench\n.\n\n\n\n\nGood Idea:\n\n\n\n\nStackOverflow account",
            "title": "Setup"
        },
        {
            "location": "/level3/level3_setup/#setup",
            "text": "You'll be doing most thing locally in this Advanced Challenge.",
            "title": "Setup"
        },
        {
            "location": "/level3/level3_setup/#getting-your-environment-set-up",
            "text": "",
            "title": "Getting your Environment Set Up"
        },
        {
            "location": "/level3/level3_setup/#hardware",
            "text": "These are some highly rated suggestions.  You may of course try out the Practice section on a CPU machine.  There's a cloud option below as well.",
            "title": "Hardware"
        },
        {
            "location": "/level3/level3_setup/#computer-laptop",
            "text": "Anything with a NVIDIA GTX 1060 (GPU) is good if you travel a lot or cannot necessarily depend on wifi.   E.g.:  https://www.razerzone.com/gaming-systems/razer-blade-pro - plan to get a 1060 w/ 256ssd + 2tb spinner  GTX 1080 (extra $2k; only get if this is your primary machine and you travel a lot/have spotty wifi).",
            "title": "Computer-Laptop"
        },
        {
            "location": "/level3/level3_setup/#computer-desktop",
            "text": "Any gaming desktop with a min GTX 1080.\u00a0   Alt 1: Custom built.\u00a0 If you go this route -> Add up your GPU ram, multiply by 2 for your min RAM.\u00a0 Get a CPU w/ 48 lanes (so you can go 2 GPUs later).  Alt 2:  https://lambdal.com/products/quad  (this is probably over kill honestly, and your electricity bill might double.\u00a0 Will make a great space heater)",
            "title": "Computer-Desktop"
        },
        {
            "location": "/level3/level3_setup/#computer-remote",
            "text": "Use Azure and set up a jupyter notebook.\u00a0 This takes more learning and understanding but is the cheapest getting started option.  It's suggested to provision a new NC-6 (or NC12) DSVM on Ubuntu, updating everything, installing the packages, adding a 1TB data disk and kicking off a password protected Jupyter Notebook in a tmux session.\u00a0 DO NOT put sensitive data on this.\u00a0 It has open ports, admin rights to the system, is password protected only and it's not believed to use SSL unless you set up a certificate.\u00a0 There are other more secure options, though they are more advanced and not covered in this getting started.",
            "title": "Computer-Remote"
        },
        {
            "location": "/level3/level3_setup/#iot-test_device",
            "text": "Raspberry Pi v3, Nvidia TX-1 or Nvidia TX-2.\u00a0 If you are feeling adventurous get a few arduinos as well.",
            "title": "IoT-Test_Device"
        },
        {
            "location": "/level3/level3_setup/#software",
            "text": "Docker for Mac or Docker for Windows (avoid Toolbox)  Anaconda  If you have a GPU  Go to  Cuda Downloads  Join Nvidia Developer program  Update your GPU drivers  Install Cuda & Cudnn    Install your packages  Open an admin cmd prompt  Pip install  plotly  (most other packages come with Anaconda)  Pip install the latest 3.6 GPU-1bit-SGD (if you got a GPU otherwise install CPU version)  CNTK 2.2  As of today this is:  pip install https://cntk.ai/PythonWheel/GPU-1bit-SGD/cntk-2.2-cp36-cp36m-win_amd64.whl      Install  Azure ML Workbench .   Good Idea:   StackOverflow account",
            "title": "Software"
        },
        {
            "location": "/level3/level3_prep/",
            "text": "Level 3 Preparation\n\n\nYou might find \nthese videos\n from \nthis\n CNN course out of Stanford useful.\n\n\nMore to come.",
            "title": "Preparation"
        },
        {
            "location": "/level3/level3_prep/#level-3-preparation",
            "text": "You might find  these videos  from  this  CNN course out of Stanford useful.  More to come.",
            "title": "Level 3 Preparation"
        },
        {
            "location": "/level3/level3_practice/",
            "text": "Level 3 Challenge\n\n\nIn this advanced Challenge, the instructions will be a little more vague and you'll need to go figure find out much on your own, part of the learning and challenge.\n\n\n\n\nThis problem set is adapted from a Custom ML Resources document written by a colleague.\n\n\n\n\nWhy do this task\n:\u00a0 Usually, beginner tutorials around ML and neural networks begin with classifying hand-written digits from the MNIST dataset.  We are going to begin with something more challenging and much of it will be dealing with data and data formats.  This is to simulate how life will likely be in real life and it's hoped you will learn how to create machine learning models more effectively and quickly in the real world.\u00a0The reason to work through the following is:\n\n\n\n\nIt will force you to read and learn from scratch.\u00a0 You will learn the different label file formats, deserializers and how things compute.\u00a0\n\n\nFor energy/manufacturing you will get .png or .jpg or .tiff files and not stuff already in the perfect format.\u00a0\n\n\nLearning this will hopefully help you understand the concept of \u201cData Packing\u201d.\u00a0\n\n\nThis is not the simplest way, but it forces greater learning.\n\n\n\n\nWorking with CNTK Locally (DLVM is also OK)\n\n\nUse the CNTK Manual as reference: \nCNTK Manual on GitHub\n\n\nThis is focusing for the Energy/Manufacturing Vertical.\n\n\n\n\nUnderstand Label Files & Mini Batch Sources:\n\n\nCTF & Image: \nhttp://dacrook.com/complex-neural-network-data-modelling-with-cntk/\n\n\nSequence: \nhttp://dacrook.com/deep-learning-match-making-with-recurrent-networks/\n\n\n\n\n\n\nImage Classification:\n\n\nStart w/ CIFAR 10 for image classification using a Jupyter Notebook (use \nCNTK Manual on GitHub\n)\n\n\nGet Data from here: \nCIFAR-10 data\n\n\nStart w/ a CTF deserializer\n\n\nUse Image library w/ numpy and CNTK's io libraries to write a ctf file containing the data in flattened arrays\n\n\n\n\n\n\nUse the Image deserializer next\n\n\nTry out a few transforms.\u00a0 You will have to read the CNTK docs pages for transforms. \nCNTK transforms\n\n\n\n\n\n\nMake sure you also create an example for \ninference\n.\n\n\nUse Scikit-learns\u2019s confusion matrix and classification_report to generate metrics.\n\n\nScikit-learn's confusion matrix\n\n\nScikit-learn's classification report\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAzure ML Workbench\n\n\n\n\n\n\nDo the same thing w/ Azure ML Workbench\n\n\n\n\nSet up\n\n\nCreate a workspace\n\n\nCreate a git repo in VSTS\n\n\nCreate a project linked to the repo\n\n\nRe-write as a single training script and execute via docker locally.\n\n\nAdd in Azure ML Workbench\u2019s logging apis.\n\n\nTry out a Convolutional Network\n\n\nUse the Azure ML Workbench Operationalization CLI to create a container.\n\n\nCreate a local container\n\n\nPull the local container and test locally\n\n\nDeploy a real time container to Azure Container Services\n\n\nTest against this.\n\n\nTIP:\u00a0 You will either send the image via the body as an array of float32 or as a byte64 encoded string.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDo the same exact exercise with CoCo: http://cocodataset.org/#home\n\n\n\n\nWhy do you think you get bad results?\n\n\n\n\n\n\nUse the Out of Box Faster-RCNN solution w/ CNTK and CoCo\n\n\n\n\nTaste of TensorFlow\n\n\nTrain a CNN on the CIFAR-10 dataset as in this \nTutorial\n.\n\n\nKey Learnings\n\n\nObject detection v.s. Classification, Data Prep and pipelines.\n\n\nPlaces to go for Help\n\n\nIf you run into trouble, email CNTK Help cntkhelp@microsoft.com and also create a stack overflow with tag \ncntk\n, then send the link to SO to CNTK Help.  Alternatively, create an Issue on the CNTK GitHub repo.",
            "title": "Practice"
        },
        {
            "location": "/level3/level3_practice/#level-3-challenge",
            "text": "In this advanced Challenge, the instructions will be a little more vague and you'll need to go figure find out much on your own, part of the learning and challenge.   This problem set is adapted from a Custom ML Resources document written by a colleague.   Why do this task :\u00a0 Usually, beginner tutorials around ML and neural networks begin with classifying hand-written digits from the MNIST dataset.  We are going to begin with something more challenging and much of it will be dealing with data and data formats.  This is to simulate how life will likely be in real life and it's hoped you will learn how to create machine learning models more effectively and quickly in the real world.\u00a0The reason to work through the following is:   It will force you to read and learn from scratch.\u00a0 You will learn the different label file formats, deserializers and how things compute.\u00a0  For energy/manufacturing you will get .png or .jpg or .tiff files and not stuff already in the perfect format.\u00a0  Learning this will hopefully help you understand the concept of \u201cData Packing\u201d.\u00a0  This is not the simplest way, but it forces greater learning.",
            "title": "Level 3 Challenge"
        },
        {
            "location": "/level3/level3_practice/#working-with-cntk-locally-dlvm-is-also-ok",
            "text": "Use the CNTK Manual as reference:  CNTK Manual on GitHub  This is focusing for the Energy/Manufacturing Vertical.   Understand Label Files & Mini Batch Sources:  CTF & Image:  http://dacrook.com/complex-neural-network-data-modelling-with-cntk/  Sequence:  http://dacrook.com/deep-learning-match-making-with-recurrent-networks/    Image Classification:  Start w/ CIFAR 10 for image classification using a Jupyter Notebook (use  CNTK Manual on GitHub )  Get Data from here:  CIFAR-10 data  Start w/ a CTF deserializer  Use Image library w/ numpy and CNTK's io libraries to write a ctf file containing the data in flattened arrays    Use the Image deserializer next  Try out a few transforms.\u00a0 You will have to read the CNTK docs pages for transforms.  CNTK transforms    Make sure you also create an example for  inference .  Use Scikit-learns\u2019s confusion matrix and classification_report to generate metrics.  Scikit-learn's confusion matrix  Scikit-learn's classification report",
            "title": "Working with CNTK Locally (DLVM is also OK)"
        },
        {
            "location": "/level3/level3_practice/#azure-ml-workbench",
            "text": "Do the same thing w/ Azure ML Workbench   Set up  Create a workspace  Create a git repo in VSTS  Create a project linked to the repo  Re-write as a single training script and execute via docker locally.  Add in Azure ML Workbench\u2019s logging apis.  Try out a Convolutional Network  Use the Azure ML Workbench Operationalization CLI to create a container.  Create a local container  Pull the local container and test locally  Deploy a real time container to Azure Container Services  Test against this.  TIP:\u00a0 You will either send the image via the body as an array of float32 or as a byte64 encoded string.         Do the same exact exercise with CoCo: http://cocodataset.org/#home   Why do you think you get bad results?    Use the Out of Box Faster-RCNN solution w/ CNTK and CoCo",
            "title": "Azure ML Workbench"
        },
        {
            "location": "/level3/level3_practice/#taste-of-tensorflow",
            "text": "Train a CNN on the CIFAR-10 dataset as in this  Tutorial .",
            "title": "Taste of TensorFlow"
        },
        {
            "location": "/level3/level3_practice/#key-learnings",
            "text": "Object detection v.s. Classification, Data Prep and pipelines.",
            "title": "Key Learnings"
        },
        {
            "location": "/level3/level3_practice/#places-to-go-for-help",
            "text": "If you run into trouble, email CNTK Help cntkhelp@microsoft.com and also create a stack overflow with tag  cntk , then send the link to SO to CNTK Help.  Alternatively, create an Issue on the CNTK GitHub repo.",
            "title": "Places to go for Help"
        }
    ]
}