{
    "docs": [
        {
            "location": "/",
            "text": "navigating-ml\n\n\nWith the advent of more data and compute power, we have a unique opportunity to create more intricate algorithms that help address accuracy issues seen in traditional machine learning.  Deep learning allows us to fine tune the fit of an algorithm to its data in an iterative manner, and to evaluate and \"feed-back\" that information during the training process for a better model.  This results in better models if enough data is provided or in some cases if there's an existing \"base model\", as is the case in transfer learning, if good quality and highly representative data is provided.\n\n\nThat being said, do you feel like there's just too much to be aware of in the ML and Deep Learning space today?  Concepts like Convolutional Neural Networks, GANs, Neural Style Transfer...and networks like AlexNet, ResNet, or Inception...frameworks like CNTK, TensorFlow, Caffe2, PyTorch...extra layers on top of those like TFLearn, Keras, Gluon, MMLSpark...\n\n\n\n\nTip:  Focus on the pipeline or workflow first and iterate on the model after.\n\n\n\n\nIf you suspect you are a beginner in this field, do you need some Python knowledge and fast?  If so go to the Getting Started section to load up on resources and once you're comfortable with data manipulation move on to the Level 1 Challenge for Dealing with Images to start building up your traditional machine learning and neural network cred.\n\n\nDo you grok the basics of ML and perhaps what a fully-connected neural network is?  Have you had some exposure to TensorFlow or PyTorch, but don't yet have deep working knowledge of Convolutional Neural Networks?  In that case, try jumping into the Level 2 section of Dealing with Images.  If it seems a little overwhelming, head back to the Level 1 area.  If it's not challenging enough, move on to the Level 3 section.\n\n\nMaybe you're a total neural network geek and you've played with PyTorch and TensorFlow a little bit now, gone through several tutorials and maybe built some custom models.  But you haven't set up your environment to include a GPU or two.  Or perhaps you haven't performed image augmentation for data sets in PyTorch?  Don't worry, by Level 3 you should be almost there and hopefully hungry for more machine learning experience.\n\n\nHere, you'll get exposed to several types, qualities and sizes of datasets.  You'll also use many key Python libraries and general Data Science tools.  These paths can be walked separately or as one big, ML onboarding.  They are intended to help you get up and running for ML partner work quickly and thoroughly.\n\n\nThat being said, feedback is always welcome especially at this early stage.  Please enjoy responsibly.\n\n\nTools and Technologies\n\n\nIncluded are:\n\n\n\n\nJupyter\n\n\nCustomVision.ai\n\n\nScikit-learn\n\n\nPyTorch\n\n\nTensorFlow\n\n\nVMs and/or Docker\n\n\n\n\nData\n\n\n\n\n\n\n\n\nDataset\n\n\nDescription\n\n\nLink\n\n\n\n\n\n\n\n\n\n\nFashion MNIST Dataset (Source: Kaggle)\n\n\nThe Fashion MNIST dataset is a good one to move on to from the hand-written digits one.  It has 60,000 28x28 training images and 10,000 test images as csv files.\n\n\nLink\n\n\n\n\n\n\nFruit Dataset (FIDS30)\n\n\nThe fruit image data set consists of 971 images of common fruit. The images are classified into 30 different fruit classes.\n\n\nLink\n\n\n\n\n\n\nCIFAR-10 (Source: Kaggle)\n\n\nThe CIFAR-10 data consists of 60,000 32x32 color images in 10 classes, with 6000 images per class. There are 50,000 training images and 10,000 test images in this official data.\n\n\nLink\n\n\n\n\n\n\nCIFAR-10 (Source: Toronto)\n\n\nSame as above\n\n\nLink",
            "title": "Main"
        },
        {
            "location": "/#navigating-ml",
            "text": "With the advent of more data and compute power, we have a unique opportunity to create more intricate algorithms that help address accuracy issues seen in traditional machine learning.  Deep learning allows us to fine tune the fit of an algorithm to its data in an iterative manner, and to evaluate and \"feed-back\" that information during the training process for a better model.  This results in better models if enough data is provided or in some cases if there's an existing \"base model\", as is the case in transfer learning, if good quality and highly representative data is provided.  That being said, do you feel like there's just too much to be aware of in the ML and Deep Learning space today?  Concepts like Convolutional Neural Networks, GANs, Neural Style Transfer...and networks like AlexNet, ResNet, or Inception...frameworks like CNTK, TensorFlow, Caffe2, PyTorch...extra layers on top of those like TFLearn, Keras, Gluon, MMLSpark...   Tip:  Focus on the pipeline or workflow first and iterate on the model after.   If you suspect you are a beginner in this field, do you need some Python knowledge and fast?  If so go to the Getting Started section to load up on resources and once you're comfortable with data manipulation move on to the Level 1 Challenge for Dealing with Images to start building up your traditional machine learning and neural network cred.  Do you grok the basics of ML and perhaps what a fully-connected neural network is?  Have you had some exposure to TensorFlow or PyTorch, but don't yet have deep working knowledge of Convolutional Neural Networks?  In that case, try jumping into the Level 2 section of Dealing with Images.  If it seems a little overwhelming, head back to the Level 1 area.  If it's not challenging enough, move on to the Level 3 section.  Maybe you're a total neural network geek and you've played with PyTorch and TensorFlow a little bit now, gone through several tutorials and maybe built some custom models.  But you haven't set up your environment to include a GPU or two.  Or perhaps you haven't performed image augmentation for data sets in PyTorch?  Don't worry, by Level 3 you should be almost there and hopefully hungry for more machine learning experience.  Here, you'll get exposed to several types, qualities and sizes of datasets.  You'll also use many key Python libraries and general Data Science tools.  These paths can be walked separately or as one big, ML onboarding.  They are intended to help you get up and running for ML partner work quickly and thoroughly.  That being said, feedback is always welcome especially at this early stage.  Please enjoy responsibly.",
            "title": "navigating-ml"
        },
        {
            "location": "/#tools-and-technologies",
            "text": "Included are:   Jupyter  CustomVision.ai  Scikit-learn  PyTorch  TensorFlow  VMs and/or Docker",
            "title": "Tools and Technologies"
        },
        {
            "location": "/#data",
            "text": "Dataset  Description  Link      Fashion MNIST Dataset (Source: Kaggle)  The Fashion MNIST dataset is a good one to move on to from the hand-written digits one.  It has 60,000 28x28 training images and 10,000 test images as csv files.  Link    Fruit Dataset (FIDS30)  The fruit image data set consists of 971 images of common fruit. The images are classified into 30 different fruit classes.  Link    CIFAR-10 (Source: Kaggle)  The CIFAR-10 data consists of 60,000 32x32 color images in 10 classes, with 6000 images per class. There are 50,000 training images and 10,000 test images in this official data.  Link    CIFAR-10 (Source: Toronto)  Same as above  Link",
            "title": "Data"
        },
        {
            "location": "/python/",
            "text": "Prerequisites\n\n\n\n\nPython 3 (Rocks!)\n\n\n\n\n(2. Algebra, calculus and some basic ML knowledge won't hurt)\n\n\nPython\n\n\nJust Starting Out\n\n\nYour first Python course\n\n\nIntro to Python for Data Science from DataCamp\n (Time:  ~4 hours)\n\n\n\n\nPython basics\n\n\nLists\n\n\nFunctions and packages\n\n\nNumpy\n\n\n\n\nYour second Python course\n\n\nA nice course from Software Carpentry on basics of Python programming with a data analysis twist.\n\n\nCourse\n (Time:  ~8 hours)\n\n\n\n\nAnalyzing Patient Data\n\n\nRepeating Actions with Loops\n\n\nStoring Multiple Values in Lists\n\n\nAnalyzing Data from Multiple Files\n\n\nMaking Choices\n\n\nCreating Functions\n\n\nErrors and Exceptions\n\n\nDefensive Programming\n\n\nDebugging\n\n\nCommand-Line Programs\n\n\n\n\nLearn about Jupyter\n\n\nNice, short video tour of Jupyter Notebooks\n\n\n\n\nGo to \nAzure Notebooks\n to check out Jupyter notebooks live and try to follow along with the video.\n\n\n\n\nProgramming and Plotting with Python\n\n\nBasics with plotting theme throughout and nice exercies from Software Carpentry.\n\n\nCourse\n (Time: ~8 hours)\n\n\n\n\nRunning and Quitting\n\n\nVariables and Assignment\n\n\nData Types and Type Conversion\n\n\nBuilt-in Functions and Help\n\n\nLibraries\n\n\nReading Tabular Data into DataFrames\n\n\nPandas DataFrames\n\n\nPlotting\n\n\nLists\n\n\nFor Loops\n\n\nLooping Over Data Sets\n\n\nWriting Functions\n\n\nVariable Scope\n\n\nConditionals\n\n\nProgramming Style\n\n\n\n\nIntermediate\n\n\nThe Data Science Handbook\n\n\nBy Jake VanderPlas, this handbook outlines everything you need to know with cool Examples and Applications, on how to get started in Data Science with Python.\n\n\nBook\n\n\nPython intro and data sciencey tools - go through in order or skip around\n\n\nPython for Data Science and Intro to Jupyter Notebooks and on Jupyter Notebooks on Azure\n - Note, solutions to exercises are in the last notebook. (Time: ~15 hours)\n\n\n\n\nBasics\n\n\nData Structures\n\n\nFunctional Programming\n\n\nSorting and Pattern Matching\n\n\nObject Oriented Programming\n\n\nBasic Difference from 2 to 3\n\n\nNumerical Computing\n\n\nData Analysis with pandas I\n\n\nData Analysis with pandas II\n\n\nMachine Learning I - ML Basics and Data Exploration\n\n\nMachine Learning II - Supervised and Unsupervised Learning\n\n\nMachine Learning III - Parameter Tuning and Model Evaluation\n\n\nVisualization\n\n\n\n\nA different take on Python and data science (either of these should cover your Python needs)\n\n\nFor a more in-depth Python course, this is a good one on edX out of UC San Diego:  \nPython for Data Science from edX\n.  (Time:  10 weeks/8-10 hours per week)\n\n\n\n\nBasic process of data science\n\n\nPython and Jupyter notebooks\n\n\nAn applied understanding of how to manipulate and analyze uncurated datasets\n\n\nBasic statistical analysis and machine learning methods\n\n\nHow to effectively visualize results\n\n\n\n\nNumerical Python, a.k.a. using the \nnumpy\n package, is essential for the data scientist\n\n\nSee my \npython/numpy.html\n article for a detailed list of \nnumpy\n resources.\n\n\nAdvanced\n\n\nSome books really worth checking out\n\n\nFor a great dive into Python in the context of ML check out this book by Sebastian Raschka (you'll get to write algorithms from scratch in pure Python!): \nPython Machine Learning (2\nnd\n Ed.)\n\n\nNot sure if this book is out yet, but Sebastian Raschka is writing a sequel with more deep learning in Python with TensorFlow: \nIntroduction to Artificial Neural Networks and Deep Learning\n.\n\n\n\"This book is concerned with the nuts and bolts of manipulating, processing, cleaning, and crunching data in Python. My goal is to offer a guide to the parts of the Python programming language and its data-oriented library ecosystem and tools that will equip you to become an effective data analyst. While 'data analysis' is in the title of the book, the focus is specifically on Python programming, libraries, and tools as opposed to data analysis methodology. This is the Python programming you need for data analysis.\"  \nPython for Data Analysis: Data Wrangling with Pandas, NumPy, and IPython by Wes McKinney\n\n\n\"Perhaps you would like to give your homemade robot a brain of its own? Make it recognize faces? Or learn to walk around? Or maybe your company has tons of data (user logs, financial data, production data, machine sensor data, hotline stats, HR reports, etc.), and more than likely you could unearth some hidden gems if you just knew where to look.\" \nHands-On Machine Learning with Scikit-Learn and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems by Aur\u00e9lien G\u00e9ron",
            "title": "Python"
        },
        {
            "location": "/python/#prerequisites",
            "text": "Python 3 (Rocks!)   (2. Algebra, calculus and some basic ML knowledge won't hurt)",
            "title": "Prerequisites"
        },
        {
            "location": "/python/#python",
            "text": "",
            "title": "Python"
        },
        {
            "location": "/python/#just-starting-out",
            "text": "Your first Python course  Intro to Python for Data Science from DataCamp  (Time:  ~4 hours)   Python basics  Lists  Functions and packages  Numpy   Your second Python course  A nice course from Software Carpentry on basics of Python programming with a data analysis twist.  Course  (Time:  ~8 hours)   Analyzing Patient Data  Repeating Actions with Loops  Storing Multiple Values in Lists  Analyzing Data from Multiple Files  Making Choices  Creating Functions  Errors and Exceptions  Defensive Programming  Debugging  Command-Line Programs   Learn about Jupyter  Nice, short video tour of Jupyter Notebooks   Go to  Azure Notebooks  to check out Jupyter notebooks live and try to follow along with the video.   Programming and Plotting with Python  Basics with plotting theme throughout and nice exercies from Software Carpentry.  Course  (Time: ~8 hours)   Running and Quitting  Variables and Assignment  Data Types and Type Conversion  Built-in Functions and Help  Libraries  Reading Tabular Data into DataFrames  Pandas DataFrames  Plotting  Lists  For Loops  Looping Over Data Sets  Writing Functions  Variable Scope  Conditionals  Programming Style",
            "title": "Just Starting Out"
        },
        {
            "location": "/python/#intermediate",
            "text": "The Data Science Handbook  By Jake VanderPlas, this handbook outlines everything you need to know with cool Examples and Applications, on how to get started in Data Science with Python.  Book  Python intro and data sciencey tools - go through in order or skip around  Python for Data Science and Intro to Jupyter Notebooks and on Jupyter Notebooks on Azure  - Note, solutions to exercises are in the last notebook. (Time: ~15 hours)   Basics  Data Structures  Functional Programming  Sorting and Pattern Matching  Object Oriented Programming  Basic Difference from 2 to 3  Numerical Computing  Data Analysis with pandas I  Data Analysis with pandas II  Machine Learning I - ML Basics and Data Exploration  Machine Learning II - Supervised and Unsupervised Learning  Machine Learning III - Parameter Tuning and Model Evaluation  Visualization   A different take on Python and data science (either of these should cover your Python needs)  For a more in-depth Python course, this is a good one on edX out of UC San Diego:   Python for Data Science from edX .  (Time:  10 weeks/8-10 hours per week)   Basic process of data science  Python and Jupyter notebooks  An applied understanding of how to manipulate and analyze uncurated datasets  Basic statistical analysis and machine learning methods  How to effectively visualize results",
            "title": "Intermediate"
        },
        {
            "location": "/python/#numerical-python-aka-using-the-numpy-package-is-essential-for-the-data-scientist",
            "text": "See my  python/numpy.html  article for a detailed list of  numpy  resources.",
            "title": "Numerical Python, a.k.a. using the numpy package, is essential for the data scientist"
        },
        {
            "location": "/python/#advanced",
            "text": "Some books really worth checking out  For a great dive into Python in the context of ML check out this book by Sebastian Raschka (you'll get to write algorithms from scratch in pure Python!):  Python Machine Learning (2 nd  Ed.)  Not sure if this book is out yet, but Sebastian Raschka is writing a sequel with more deep learning in Python with TensorFlow:  Introduction to Artificial Neural Networks and Deep Learning .  \"This book is concerned with the nuts and bolts of manipulating, processing, cleaning, and crunching data in Python. My goal is to offer a guide to the parts of the Python programming language and its data-oriented library ecosystem and tools that will equip you to become an effective data analyst. While 'data analysis' is in the title of the book, the focus is specifically on Python programming, libraries, and tools as opposed to data analysis methodology. This is the Python programming you need for data analysis.\"   Python for Data Analysis: Data Wrangling with Pandas, NumPy, and IPython by Wes McKinney  \"Perhaps you would like to give your homemade robot a brain of its own? Make it recognize faces? Or learn to walk around? Or maybe your company has tons of data (user logs, financial data, production data, machine sensor data, hotline stats, HR reports, etc.), and more than likely you could unearth some hidden gems if you just knew where to look.\"  Hands-On Machine Learning with Scikit-Learn and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems by Aur\u00e9lien G\u00e9ron",
            "title": "Advanced"
        },
        {
            "location": "/python/numpy/",
            "text": "A List of \nnumpy\n resources\n\n\nNumPy stands for Numerical Python.  It's widely used in Linear Algebra applications and has become a \nde facto\n library for use in Machine Learning.  It uses memory efficiently and is mostly implemented in C, thus is a very efficient option for numerical calculations (see more in Reference #3 by Sebastian Raschka).  I've made a list of resources for the \nnumpy\n library to help someone new or someone in need of a good reference later on.  It was created by Travis Oliphant in 2005 (also the creator of SciPy).  The package lives on GitHub (\nLink\n).\n\n\nListing.  In no special order.\n\n\n\n\nQuickstart tutorial.  From the \nscipy\n docs.  Short, but good starting point. \nRef\n\n\nIntroduction to NumPy.  A nice whole chapter on \nnumpy\n by Jake VanderPlas. \nRef\n\n\nIntroduction to Numpy.  A really nice quick tour as an appendix to a deep learning book by Sebastian Raschka \nRef\n and as a \nNotebook\n\n\nNumerical Scientific Computing.  Quick tour with exercises by Micheleen Harris.  \nNotebook\n\n\nNumPy Practice.  With some nice notes on Linear Algebra operations in \nnumpy\n by Tirthajyoti Sarkar.  \nNotebook\n\n\n\n\nA listing of Linear Algebra resources to go along with this\n\n\n\n\nStanford comprehensive Linear Algebra review document by Zico Kolter.  \nRef\n\n\n\n\nLinear Algebra Review (Andrew Ng).\n\n\n\n\nMatrices and Vectors. \nVideo\n\n\nAddition And Scalar Multiplication. \nVideo\n\n\nMatrix Vector Multiplication.  \nVideo\n\n\nMatrix-Matrix Multiplication.  \nVideo\n\n\nMatrix Multiplication Properties.  \nVideo\n\n\nInverse And Transpose.  \nVideo\n\n\n\n\n\n\n\n\nLinear Algebra youtube channel by Khan Academy \nVideos\n\n\n\n\nCoding the Matrix.  \nBook\n\n\n\n\nExercise:  Follow along with these courses by doing things concurrently in \nnumpy\n.\n\n\nThere are likely many more great resources out there so feel free to create an issue on this \nGitHub repo\n letting me know about yours or others.",
            "title": "NumPy and Linear Algebra"
        },
        {
            "location": "/python/numpy/#a-list-of-numpy-resources",
            "text": "NumPy stands for Numerical Python.  It's widely used in Linear Algebra applications and has become a  de facto  library for use in Machine Learning.  It uses memory efficiently and is mostly implemented in C, thus is a very efficient option for numerical calculations (see more in Reference #3 by Sebastian Raschka).  I've made a list of resources for the  numpy  library to help someone new or someone in need of a good reference later on.  It was created by Travis Oliphant in 2005 (also the creator of SciPy).  The package lives on GitHub ( Link ).",
            "title": "A List of numpy resources"
        },
        {
            "location": "/python/numpy/#listing-in-no-special-order",
            "text": "Quickstart tutorial.  From the  scipy  docs.  Short, but good starting point.  Ref  Introduction to NumPy.  A nice whole chapter on  numpy  by Jake VanderPlas.  Ref  Introduction to Numpy.  A really nice quick tour as an appendix to a deep learning book by Sebastian Raschka  Ref  and as a  Notebook  Numerical Scientific Computing.  Quick tour with exercises by Micheleen Harris.   Notebook  NumPy Practice.  With some nice notes on Linear Algebra operations in  numpy  by Tirthajyoti Sarkar.   Notebook",
            "title": "Listing.  In no special order."
        },
        {
            "location": "/python/numpy/#a-listing-of-linear-algebra-resources-to-go-along-with-this",
            "text": "Stanford comprehensive Linear Algebra review document by Zico Kolter.   Ref   Linear Algebra Review (Andrew Ng).   Matrices and Vectors.  Video  Addition And Scalar Multiplication.  Video  Matrix Vector Multiplication.   Video  Matrix-Matrix Multiplication.   Video  Matrix Multiplication Properties.   Video  Inverse And Transpose.   Video     Linear Algebra youtube channel by Khan Academy  Videos   Coding the Matrix.   Book   Exercise:  Follow along with these courses by doing things concurrently in  numpy .  There are likely many more great resources out there so feel free to create an issue on this  GitHub repo  letting me know about yours or others.",
            "title": "A listing of Linear Algebra resources to go along with this"
        },
        {
            "location": "/python/nlp/",
            "text": "Natural Language Processing Resources\n\n\nThis is a set of materials to learn and practice NLP.  Can also be used as general reference, such as the list of important libraries and links to course materials.  (Work In Progress)\n\n\nTutorials\n\n\n\n\n\n\n\n\nTopic\n\n\nTitle/Description\n\n\nLink\n\n\n\n\n\n\n\n\n\n\nTopic Modeling\n\n\nTopic modeling from Gensim official Docs\n\n\nTutorial\n\n\n\n\n\n\nTopic Modeling and Clustering\n\n\nA topic identification and document clustering algorithm tutorial with Gensim/NLTK from PyCon\n\n\nVideo\n\n\n\n\n\n\nIntent and Entity Recognition\n\n\nLanguage Understanding with Recurrent Networks from CNTK official Docs\n\n\nTutorial\n\n\n\n\n\n\nWord2Vec\n\n\nVector Representations of Words from TensorFlow official Docs\n\n\nTutorial\n\n\n\n\n\n\nText categorization\n\n\nAnalysing a collection of text documents from Scikit-Learn official Docs\n\n\nTutorial\n\n\n\n\n\n\nSequence to Sequence\n\n\nA tutorial on how to summarize text and generate features using deep learning with Keras and TensorFlow\n\n\nTutorial\n\n\n\n\n\n\n\n\nCourses and Course Materials\n\n\n\n\nStanford Deep Learning for NLP (cs224n) \nCourse Material\n\n\n\n\nExamples - Try Me!\n\n\n\n\nDocument clustering with k-means official \nscikit-learn\n \nExample\n\n\nFeaturize free-form text data using \nmmlspark\n on top of primitives in SparkML via a single transformer in this official \nmmlspark\n \nNotebook\n\n\nSequence Classification with CNTK \nExample\n\n\nSequence2Sequence with CNTK \nExample\n\n\n\n\nNLP-Specific Packages\n\n\n\n\ngensim\n:  topic modelling \nDocs\n - good for word2vec, semantic similarity, LDA, LSA, etc.\n\n\nnltk\n:  Natural Language Toolkit \nDocs\n - good for tokenization, stemming, tagging, parsing, corpora, etc.\n\n\nspacy\n:  Efficient and Backed by ANNs NLP Toolkit \nDocs\n - good for parsing, tagging, entity recognition, text categorization, phrase matching, etc.\n\n\nallennlp\n:  Deep Learning for NLP from AllenNLP built on PyTorch \nRef\n - good for conditional random field, encoders/decoders, reading comprehension, semantic role, etc.\n\n\n\n\nBlog Articles\n\n\n\n\n\n\n\n\nTopic\n\n\nTitle/Description\n\n\nLink\n\n\n\n\n\n\n\n\n\n\nBasics\n\n\n7 types of Artificial Neural Networks for Natural Language Processing\n\n\nLink\n\n\n\n\n\n\nTF/IDF\n\n\nCalculating TF/IDF on How I met your mother transcripts (with \nscikit-learn\n)\n\n\nLink\n\n\n\n\n\n\nGeneral/Sentiment Analysis\n\n\nBreakthrough Research Papers and Models for Sentiment Analysis\n\n\nLink\n\n\n\n\n\n\n\n\n\n\nLink\n\n\n\n\n\n\n\n\nPapers\n\n\n\n\n\n\n\n\nTopic\n\n\nTitle/Description\n\n\nAuthor(s)\n\n\nLink\n\n\n\n\n\n\n\n\n\n\nText Classification\n\n\nFine-tuned Language Models for Text Classification (with Transfer Learning)\n\n\nJeremy Howard, Sebastian Ruder\n\n\nLink\n\n\n\n\n\n\n\n\nNLP at Scale\n\n\n\n\nDocument classification with \npyspark\n with HDInsight on Azure \nDoc\n\n\n\n\nKaggle\n\n\n\n\nToxic Comment Classification Challenge \nCompetition\n\n\n\n\nBooks\n\n\nTBD\n\n\nExercises - Try Me!\n\n\n\n\n\n\n\n\nTopic\n\n\nTitle/Description\n\n\nLink\n\n\n\n\n\n\n\n\n\n\nSentiment Analysis\n\n\nBuild a sentiment analysis / polarity model \nscikit-learn\n\n\nExercise\n and \nCode to start\n\n\n\n\n\n\n\n\nList updated 2017-01-26",
            "title": "Natural Language Processing Resources"
        },
        {
            "location": "/python/nlp/#natural-language-processing-resources",
            "text": "This is a set of materials to learn and practice NLP.  Can also be used as general reference, such as the list of important libraries and links to course materials.  (Work In Progress)",
            "title": "Natural Language Processing Resources"
        },
        {
            "location": "/python/nlp/#tutorials",
            "text": "Topic  Title/Description  Link      Topic Modeling  Topic modeling from Gensim official Docs  Tutorial    Topic Modeling and Clustering  A topic identification and document clustering algorithm tutorial with Gensim/NLTK from PyCon  Video    Intent and Entity Recognition  Language Understanding with Recurrent Networks from CNTK official Docs  Tutorial    Word2Vec  Vector Representations of Words from TensorFlow official Docs  Tutorial    Text categorization  Analysing a collection of text documents from Scikit-Learn official Docs  Tutorial    Sequence to Sequence  A tutorial on how to summarize text and generate features using deep learning with Keras and TensorFlow  Tutorial",
            "title": "Tutorials"
        },
        {
            "location": "/python/nlp/#courses-and-course-materials",
            "text": "Stanford Deep Learning for NLP (cs224n)  Course Material",
            "title": "Courses and Course Materials"
        },
        {
            "location": "/python/nlp/#examples-try-me",
            "text": "Document clustering with k-means official  scikit-learn   Example  Featurize free-form text data using  mmlspark  on top of primitives in SparkML via a single transformer in this official  mmlspark   Notebook  Sequence Classification with CNTK  Example  Sequence2Sequence with CNTK  Example",
            "title": "Examples - Try Me!"
        },
        {
            "location": "/python/nlp/#nlp-specific-packages",
            "text": "gensim :  topic modelling  Docs  - good for word2vec, semantic similarity, LDA, LSA, etc.  nltk :  Natural Language Toolkit  Docs  - good for tokenization, stemming, tagging, parsing, corpora, etc.  spacy :  Efficient and Backed by ANNs NLP Toolkit  Docs  - good for parsing, tagging, entity recognition, text categorization, phrase matching, etc.  allennlp :  Deep Learning for NLP from AllenNLP built on PyTorch  Ref  - good for conditional random field, encoders/decoders, reading comprehension, semantic role, etc.",
            "title": "NLP-Specific Packages"
        },
        {
            "location": "/python/nlp/#blog-articles",
            "text": "Topic  Title/Description  Link      Basics  7 types of Artificial Neural Networks for Natural Language Processing  Link    TF/IDF  Calculating TF/IDF on How I met your mother transcripts (with  scikit-learn )  Link    General/Sentiment Analysis  Breakthrough Research Papers and Models for Sentiment Analysis  Link      Link",
            "title": "Blog Articles"
        },
        {
            "location": "/python/nlp/#papers",
            "text": "Topic  Title/Description  Author(s)  Link      Text Classification  Fine-tuned Language Models for Text Classification (with Transfer Learning)  Jeremy Howard, Sebastian Ruder  Link",
            "title": "Papers"
        },
        {
            "location": "/python/nlp/#nlp-at-scale",
            "text": "Document classification with  pyspark  with HDInsight on Azure  Doc",
            "title": "NLP at Scale"
        },
        {
            "location": "/python/nlp/#kaggle",
            "text": "Toxic Comment Classification Challenge  Competition",
            "title": "Kaggle"
        },
        {
            "location": "/python/nlp/#books",
            "text": "TBD",
            "title": "Books"
        },
        {
            "location": "/python/nlp/#exercises-try-me",
            "text": "Topic  Title/Description  Link      Sentiment Analysis  Build a sentiment analysis / polarity model  scikit-learn  Exercise  and  Code to start     List updated 2017-01-26",
            "title": "Exercises - Try Me!"
        },
        {
            "location": "/level1/level1_setup/",
            "text": "Setup\n\n\n\n\n\n\nAnaconda3 Python (Recommended versions:  Anaconda3 4.1.1 for Python 3.5.2 recommended, Anaconda3 4.3.1 for Python 3.6 ok, too)\n\n\n\n\nThis will allow you to create \nconda\n environments to \"contain\" your projects and Python versions.  In fact you can use your current Anaconda or Miniconda Python to install other Python versions from the command line \nRef\n\n\n\n\n\n\n\n\nJupyter notebook with Python and ML ecosystem (local, service or cloud)\n\n\n\n\nFor the first part of the Beginner Challenge, you can use \nAzure Notebooks\n service as your Python environment as it's a Jupyter notebook system and free.  Or you can set up Jupyter notebooks locally with the ML ecosystem (\nnumpy\n, \npandas\n, \nscikit-learn\n, \nopencv-python\n etc.).\n\n\nMore on Jupyter from their \nDocs\n.\n\n\n\n\n\n\n\n\n\n\nThis is a good chance to build up some Data Science tools locally - nice (from experience) when you have spotty wifi.\n\n\n\n\n\n\nDocker for Mac or Docker for Windows (avoid Toolbox)\n\n\nThis is to aid in creating reproducible setups so you can share with others so they can do it, too!\n\n\n\n\n\n\n\n\nGood Idea:\n\n\n\n\nStackOverflow account\n\n\n\n\nAdditional Resources\n\n\n\n\nThe Stats/ML StackExchange is a useful place to pose questions about ML and stats \nLink",
            "title": "Setup"
        },
        {
            "location": "/level1/level1_setup/#setup",
            "text": "Anaconda3 Python (Recommended versions:  Anaconda3 4.1.1 for Python 3.5.2 recommended, Anaconda3 4.3.1 for Python 3.6 ok, too)   This will allow you to create  conda  environments to \"contain\" your projects and Python versions.  In fact you can use your current Anaconda or Miniconda Python to install other Python versions from the command line  Ref     Jupyter notebook with Python and ML ecosystem (local, service or cloud)   For the first part of the Beginner Challenge, you can use  Azure Notebooks  service as your Python environment as it's a Jupyter notebook system and free.  Or you can set up Jupyter notebooks locally with the ML ecosystem ( numpy ,  pandas ,  scikit-learn ,  opencv-python  etc.).  More on Jupyter from their  Docs .      This is a good chance to build up some Data Science tools locally - nice (from experience) when you have spotty wifi.    Docker for Mac or Docker for Windows (avoid Toolbox)  This is to aid in creating reproducible setups so you can share with others so they can do it, too!",
            "title": "Setup"
        },
        {
            "location": "/level1/level1_setup/#good-idea",
            "text": "StackOverflow account",
            "title": "Good Idea:"
        },
        {
            "location": "/level1/level1_setup/#additional-resources",
            "text": "The Stats/ML StackExchange is a useful place to pose questions about ML and stats  Link",
            "title": "Additional Resources"
        },
        {
            "location": "/level1/level1_prep/",
            "text": "Level 1 Preparation\n\n\nTo begin at this level you should have:\n\n\n\n\nFamiliarity with Python 3 for general purpose programming.  See the \nPython\n section for more.\n\n\nWorking knowledge of traditional ML (when to use what)\n\n\nBasic data mining skills\n\n\n\n\nConcepts\n\n\nDealing with Image Data\n\n\n\n\nRead through this excellent first taste of Image Classification from this Stanford CS231n course \nRef\n\n\n\n\nNeural Networks\n\n\n\n\nRead through \nthis\n excellent explanation of a single-layer neural network.  This information will lay the foundation for these sets of challenges and help you get started from the ground-up, quickly with key concepts and Python code snippets.\n\n\n\n\nTools\n\n\n\n\nGit and GitHub for version control.\n\n\nJupyter notebook skills. \nChapter 1 Python Data Science Handbook\n\n\nGet a good grasp of Python for data tasks:\n\n\nHow to read data (matplotlib, Pillow/PIL, opencv)\n\n\nHow to manipulate data (numpy, pandas, scikit-learn) \n\n\nHow to plot data (matplotlib, plotly)\n\n\nTraditional ML (scikit-learn)\n\n\n\n\n\n\n\n\nA Learning Path is under dev to cover the above topics in linear fashion\n\n\nAdditional Resources\n\n\nScikit-Learn\n\n\nExcellent 3-hr scikit-learn tutorials from PyCon 2015:\n\n\n\n\nWatch \nthis\n scikit-learn tutorial by Jake VanderPlas (Part 1) and \nthe next\n tutorial by Olivier Grisel (Part 2).\n\n\n\n\nLearn about ML and Python scikit-learn in this \nvideo series",
            "title": "Preparation"
        },
        {
            "location": "/level1/level1_prep/#level-1-preparation",
            "text": "To begin at this level you should have:   Familiarity with Python 3 for general purpose programming.  See the  Python  section for more.  Working knowledge of traditional ML (when to use what)  Basic data mining skills",
            "title": "Level 1 Preparation"
        },
        {
            "location": "/level1/level1_prep/#concepts",
            "text": "",
            "title": "Concepts"
        },
        {
            "location": "/level1/level1_prep/#dealing-with-image-data",
            "text": "Read through this excellent first taste of Image Classification from this Stanford CS231n course  Ref",
            "title": "Dealing with Image Data"
        },
        {
            "location": "/level1/level1_prep/#neural-networks",
            "text": "Read through  this  excellent explanation of a single-layer neural network.  This information will lay the foundation for these sets of challenges and help you get started from the ground-up, quickly with key concepts and Python code snippets.",
            "title": "Neural Networks"
        },
        {
            "location": "/level1/level1_prep/#tools",
            "text": "Git and GitHub for version control.  Jupyter notebook skills.  Chapter 1 Python Data Science Handbook  Get a good grasp of Python for data tasks:  How to read data (matplotlib, Pillow/PIL, opencv)  How to manipulate data (numpy, pandas, scikit-learn)   How to plot data (matplotlib, plotly)  Traditional ML (scikit-learn)     A Learning Path is under dev to cover the above topics in linear fashion",
            "title": "Tools"
        },
        {
            "location": "/level1/level1_prep/#additional-resources",
            "text": "",
            "title": "Additional Resources"
        },
        {
            "location": "/level1/level1_prep/#scikit-learn",
            "text": "Excellent 3-hr scikit-learn tutorials from PyCon 2015:   Watch  this  scikit-learn tutorial by Jake VanderPlas (Part 1) and  the next  tutorial by Olivier Grisel (Part 2).   Learn about ML and Python scikit-learn in this  video series",
            "title": "Scikit-Learn"
        },
        {
            "location": "/level1/level1_practice/",
            "text": "Level 1 Challenge\n\n\nIt is recommended that you have completed the \nLeve 1 Preparation\n.\n\n\nIn this Beginner Challenge you'll learn about basic ML and neural networks hands-on with Jupyter notebooks and Python.  You'll be introduced to scikit-learn, CNTK, and TensorFlow as Python packages commonly used in data manipulation and data science.  \n\n\nHere and throughout these practice exercises you'll work with the following image datasets: the fruit FIDS30 dataset, the Kaggle Fashion MNIST dataset and the CIFAR-10 (tiny images) dataset.\n\n\nCustom Vision (Microsoft)\n\n\nDownload the \nfruit dataset\n and build a fruit image classifier with two fruit classes using \nhttps://customvision.ai/\n.\n\n\nAfter you have done some training above, create a Python script to \"pixel-normalize\" the images prior to training the model and retrain to see your new Precision and Recall.\n\n\n\n\n\n\nSome defintions.  \nPrecision\n:  if a tag is precicted by your classifier, how likely is it that it is right?  \nRecall\n:  out of the tags that should be classified as right, what percentage did your classifier correctly find?\n\n\n\n\nFirst Custom ML (Open Source Tools)\n\n\nFor these two problems, it is recommended to go through the code from the original source line by line in whatever fashion you see fit so that you really understand what is happening.\n\n\n\n\nTIPS:  Place all imports at the top of the notebook.  Call the training data something consistent thoughout all of your work (X_train -> training data, y_train -> labels, X_test -> test data...).\n\n\n\n\nImage Classification\n\n\nCreate a Python program to classify images from Fashion MNIST Dataset (get \nhere\n) leveraging code samples from the Python Data Science Handbook - \nRef\n.  Refer to Chapter 2 and 3 of this Handbook for information on data manipulation in Python if not already familiar.\n\n\nDo this in a Jupyter notebook (any service or locally) - recall you learned about this tool the \nSetup Section\n.  \n\n\nIt might help to examine the existing data format for \nsklearn.datasets.load_digits\n so that you can convert into that format to utilize the algorithms in \nsklearn\n (scikit-learn).  \n\n\n\n\nWhat did you find?  Which fashion item has the best accuracy, which the worst?  Why do you think that is?  Is there a way you could imagine improving this model?\n\n\nTry a different model\n\n\nScale the images (in \nsklearn\n) and check the accuracy of the model again.  Did it improve or worsen?\n\n\n\n\nObject Detection\n\n\n\n\nIn the real world, data is rarely so uniform and simple pixels will not be suitable: this has led to a large literature on feature extraction methods for image data.\n\n\n\n\nCreate a Python program to detect cats in 2D images by leveraging code samples from the Python Data Science Handbook - \nRef\n.  Refer to Chapter 2 and 3 of this Handbook for information on data manipulation in Python if not already familiar.\n\n\nDo this in a Jupyter notebook (any service or locally) - recall you learned about this tool the \nSetup Section\n.  \n\n\nIt might help to examine the existing data format for \nsklearn.datasets.fetch_lfw_people\n so that you can convert into that format to utilize the algorithms in \nsklearn\n (scikit-learn) to create this detector.  \n\n\n\n\nWhat other confounding factors are there for images other than illumination, you think?\n\n\nPlot the original image along with the \nskimage.rgb2gray\n version and the HOG representation.  See how this works in \nmatplotlib\n.  What does \nskimage.rgb2gray\n actually do?\n\n\nCan you scale the new image of the astronaut with the \nPIL\n module instead?  This module is very powerful and good to know about (as well as \nopencv\n)?\n\n\nTry out the model on the entire test image instead.  What do you find out?\n\n\nTry using sliding windows with a variety of sizes (aspect ratios).  What do you find out?\n\n\nRead in a new image that contains a face and on one that does not and try your model on that.\n\n\nAugment the data to expand the training and test datasets (e.g. use a library like \nimgaug\n) and retrain and test.\n\n\nExtra credit\n:  Implement Non-Maximum Suppression in Python to find the single best bounding box of a group of bounding boxes as are found above.  Apply this to the astronaut image.\n\n\n\n\nBasic Neural Nets\n\n\nThe purpose of the Basic Neural Nets exercises are to familiarize you with how a simple artificial neuron works and then set of a few neurons to form a network (artificial neural network) - all from the ground-up - this knowledge will serve you well.  It will really get to the core of neural nets and give you a perfect \"from scratch\" introduction (the code template already exists around the infamous iris dataset, you'll just make it work with some fashionable images).  If we want to get to know deep neural nets, why not dive in deep to start!\n\n\n\n\nUse \nAzure Notebooks\n for this tutorial.  Fire up a blank Python 3.5 Jupyter notebook for this.\n\n\nGet the following sample image dataset loaded in your Jupyter notebook: \ntrain and test Fashion MNIST Dataset (Source: Kaggle)\n\n\nAdapt a from-scratch Perceptron as in this \nJupyter notebook\n to train and test on the image dataset.\n\n\nUse the URL option when opening up a new notebook in Azure Notebooks\n\n\nOr, download by right clicking on \"Raw\" and \"Save link as...\"\n\n\nRe-implement the Perceptron with \nsklearn\n (scikit-learn)\n\n\n\n\n\n\nAdapt a from-scratch Multilayer Perceptron (MLP) as in this \nJupyter notebook\n\n\nUse the URL option when opening up a new notebook in Azure Notebooks\n\n\nOr, download by right clicking on \"Raw\" and \"Save link as...\"\n\n\nRe-implement the MLP with \nsklearn\n\n\n\n\n\n\n\n\nMoving On\n\n\nNow it is time to move on to Level 2 Preparation.\n\n\nAdditional Help\n\n\n\n\nStackOverflow with \nsklearn\n, \njupyter\n\n\nFor Custom Vision you can email \ncustomvisionteam@microsoft.com\n.",
            "title": "Practice"
        },
        {
            "location": "/level1/level1_practice/#level-1-challenge",
            "text": "It is recommended that you have completed the  Leve 1 Preparation .  In this Beginner Challenge you'll learn about basic ML and neural networks hands-on with Jupyter notebooks and Python.  You'll be introduced to scikit-learn, CNTK, and TensorFlow as Python packages commonly used in data manipulation and data science.    Here and throughout these practice exercises you'll work with the following image datasets: the fruit FIDS30 dataset, the Kaggle Fashion MNIST dataset and the CIFAR-10 (tiny images) dataset.",
            "title": "Level 1 Challenge"
        },
        {
            "location": "/level1/level1_practice/#custom-vision-microsoft",
            "text": "Download the  fruit dataset  and build a fruit image classifier with two fruit classes using  https://customvision.ai/ .  After you have done some training above, create a Python script to \"pixel-normalize\" the images prior to training the model and retrain to see your new Precision and Recall.    Some defintions.   Precision :  if a tag is precicted by your classifier, how likely is it that it is right?   Recall :  out of the tags that should be classified as right, what percentage did your classifier correctly find?",
            "title": "Custom Vision (Microsoft)"
        },
        {
            "location": "/level1/level1_practice/#first-custom-ml-open-source-tools",
            "text": "For these two problems, it is recommended to go through the code from the original source line by line in whatever fashion you see fit so that you really understand what is happening.   TIPS:  Place all imports at the top of the notebook.  Call the training data something consistent thoughout all of your work (X_train -> training data, y_train -> labels, X_test -> test data...).",
            "title": "First Custom ML (Open Source Tools)"
        },
        {
            "location": "/level1/level1_practice/#image-classification",
            "text": "Create a Python program to classify images from Fashion MNIST Dataset (get  here ) leveraging code samples from the Python Data Science Handbook -  Ref .  Refer to Chapter 2 and 3 of this Handbook for information on data manipulation in Python if not already familiar.  Do this in a Jupyter notebook (any service or locally) - recall you learned about this tool the  Setup Section .    It might help to examine the existing data format for  sklearn.datasets.load_digits  so that you can convert into that format to utilize the algorithms in  sklearn  (scikit-learn).     What did you find?  Which fashion item has the best accuracy, which the worst?  Why do you think that is?  Is there a way you could imagine improving this model?  Try a different model  Scale the images (in  sklearn ) and check the accuracy of the model again.  Did it improve or worsen?",
            "title": "Image Classification"
        },
        {
            "location": "/level1/level1_practice/#object-detection",
            "text": "In the real world, data is rarely so uniform and simple pixels will not be suitable: this has led to a large literature on feature extraction methods for image data.   Create a Python program to detect cats in 2D images by leveraging code samples from the Python Data Science Handbook -  Ref .  Refer to Chapter 2 and 3 of this Handbook for information on data manipulation in Python if not already familiar.  Do this in a Jupyter notebook (any service or locally) - recall you learned about this tool the  Setup Section .    It might help to examine the existing data format for  sklearn.datasets.fetch_lfw_people  so that you can convert into that format to utilize the algorithms in  sklearn  (scikit-learn) to create this detector.     What other confounding factors are there for images other than illumination, you think?  Plot the original image along with the  skimage.rgb2gray  version and the HOG representation.  See how this works in  matplotlib .  What does  skimage.rgb2gray  actually do?  Can you scale the new image of the astronaut with the  PIL  module instead?  This module is very powerful and good to know about (as well as  opencv )?  Try out the model on the entire test image instead.  What do you find out?  Try using sliding windows with a variety of sizes (aspect ratios).  What do you find out?  Read in a new image that contains a face and on one that does not and try your model on that.  Augment the data to expand the training and test datasets (e.g. use a library like  imgaug ) and retrain and test.  Extra credit :  Implement Non-Maximum Suppression in Python to find the single best bounding box of a group of bounding boxes as are found above.  Apply this to the astronaut image.",
            "title": "Object Detection"
        },
        {
            "location": "/level1/level1_practice/#basic-neural-nets",
            "text": "The purpose of the Basic Neural Nets exercises are to familiarize you with how a simple artificial neuron works and then set of a few neurons to form a network (artificial neural network) - all from the ground-up - this knowledge will serve you well.  It will really get to the core of neural nets and give you a perfect \"from scratch\" introduction (the code template already exists around the infamous iris dataset, you'll just make it work with some fashionable images).  If we want to get to know deep neural nets, why not dive in deep to start!   Use  Azure Notebooks  for this tutorial.  Fire up a blank Python 3.5 Jupyter notebook for this.  Get the following sample image dataset loaded in your Jupyter notebook:  train and test Fashion MNIST Dataset (Source: Kaggle)  Adapt a from-scratch Perceptron as in this  Jupyter notebook  to train and test on the image dataset.  Use the URL option when opening up a new notebook in Azure Notebooks  Or, download by right clicking on \"Raw\" and \"Save link as...\"  Re-implement the Perceptron with  sklearn  (scikit-learn)    Adapt a from-scratch Multilayer Perceptron (MLP) as in this  Jupyter notebook  Use the URL option when opening up a new notebook in Azure Notebooks  Or, download by right clicking on \"Raw\" and \"Save link as...\"  Re-implement the MLP with  sklearn",
            "title": "Basic Neural Nets"
        },
        {
            "location": "/level1/level1_practice/#moving-on",
            "text": "Now it is time to move on to Level 2 Preparation.",
            "title": "Moving On"
        },
        {
            "location": "/level1/level1_practice/#additional-help",
            "text": "StackOverflow with  sklearn ,  jupyter  For Custom Vision you can email  customvisionteam@microsoft.com .",
            "title": "Additional Help"
        },
        {
            "location": "/level2/level2_setup/",
            "text": "Setup\n\n\nCloud\n\n\n\n\n(Deploy when ready if you don't have it yet) \nLinux (Ubuntu) Deep Learning Virtual Machine\n Standard NC6\n\n\n\n\n\n\nTip: place everything for this set of challenges in the same resource group to tear down together at the end.\n\n\nTensorFlow and PyTorch can be found on all Linux and Windows Data Science Virtual Machines and Deep Learning Virtual Machines along with a long list of common data science tools - see \nDocs\n\n\n\n\n\n\nEnsure Jupyter notebooks are working.\n\n\n\"access the Jupyter notebook server from any host. Just navigate in the browser to \nhttps://<VM DNS name or IP Address>:8000/\n\" (\nDoc\n - check out \"Jupyter notebook\" for more)\n\n\n\n\n\n\n\n\nLocal via Docker\n\n\nHere are the instructions for a generic scientific and deep learning custom Linux VM with Jupyterhub (Running Locally):\n\n\n\n\nGitHub project - \nRef\n\n\n\n\nLocal Non-Docker\n\n\nHere, it's assumed you know what you are doing and can set up the scientific stack.\n\n\nImportant additional libraries:\n\n\n\n\nJupyter - \nRef\n\n\nPyTorch - \nRef",
            "title": "Setup"
        },
        {
            "location": "/level2/level2_setup/#setup",
            "text": "",
            "title": "Setup"
        },
        {
            "location": "/level2/level2_setup/#cloud",
            "text": "(Deploy when ready if you don't have it yet)  Linux (Ubuntu) Deep Learning Virtual Machine  Standard NC6    Tip: place everything for this set of challenges in the same resource group to tear down together at the end.  TensorFlow and PyTorch can be found on all Linux and Windows Data Science Virtual Machines and Deep Learning Virtual Machines along with a long list of common data science tools - see  Docs    Ensure Jupyter notebooks are working.  \"access the Jupyter notebook server from any host. Just navigate in the browser to  https://<VM DNS name or IP Address>:8000/ \" ( Doc  - check out \"Jupyter notebook\" for more)",
            "title": "Cloud"
        },
        {
            "location": "/level2/level2_setup/#local-via-docker",
            "text": "Here are the instructions for a generic scientific and deep learning custom Linux VM with Jupyterhub (Running Locally):   GitHub project -  Ref",
            "title": "Local via Docker"
        },
        {
            "location": "/level2/level2_setup/#local-non-docker",
            "text": "Here, it's assumed you know what you are doing and can set up the scientific stack.  Important additional libraries:   Jupyter -  Ref  PyTorch -  Ref",
            "title": "Local Non-Docker"
        },
        {
            "location": "/level2/level2_prep/",
            "text": "Level 2 Preparation\n\n\nNow it's time to really learn about PyTorch and classifiers such as logistic regression, multilayer perceptron, and convolutional network (CNN/ConvNet) classifiers.  The MNIST hand-written digits dataset is used in the following course to classify grey-scale images of digits.  We'll use this code in our Challenge section so go ahead and get familiar with it now by taking this course.\n\n\n\n\nLearn concepts around neural networks for image applications and be able to answer these questions.\n\n\nList the differences between a Convolutional (ConvNet/CNN) and regular Dense Neural Network.\n\n\nList and give examples of the tunable hyperparameters one can find in a ConvNet.\n...",
            "title": "Preparation"
        },
        {
            "location": "/level2/level2_prep/#level-2-preparation",
            "text": "Now it's time to really learn about PyTorch and classifiers such as logistic regression, multilayer perceptron, and convolutional network (CNN/ConvNet) classifiers.  The MNIST hand-written digits dataset is used in the following course to classify grey-scale images of digits.  We'll use this code in our Challenge section so go ahead and get familiar with it now by taking this course.   Learn concepts around neural networks for image applications and be able to answer these questions.  List the differences between a Convolutional (ConvNet/CNN) and regular Dense Neural Network.  List and give examples of the tunable hyperparameters one can find in a ConvNet.\n...",
            "title": "Level 2 Preparation"
        },
        {
            "location": "/level2/level2_practice/",
            "text": "Level 2 Challenge\n\n\nIn this intermediate Challenge, you'll apply what you've learned in the edX Deep Learning Explained course, leveraging the Jupyter notebooks you became familiar with in the course.  You'll start exploring the CIFAR-10 dataset along with other datsets in PyTorch and TensorFlow.\n\n\nAdapt Deep Learning Code\n\n\nImage Classification\n\n\nInstructions to practice image classification with PyTorch\n\n\n\n\nGet the CIFAR-10 dataset\n\n\nRun the download script: \n\n\n\n\n\n\nNow let's begin working with some code.  Log into the Jupyter\n\n\nIn a code cell \n! git clone ___\n\n\nOpen this notebook:\n\n\nModify the notebook to work with the CIFAR-10\n\n\nRemember you're working with RGB images instead of grayscale\n\n\n\n\n\n\nWhat is the resulting average test error?  Why is this value so different from the MNIST result?  What hyperparameters can you modify to fix this?\n\n\n\n\nExtra Credit\n\n\n\n\nGo online and find 5 png's of cats and dogs.  Reshape them and pad them to be 32x32 pixels using the Python Pillow library (see \nImageOps\n). Test the network with these, following the guidelines and lessons you learned thus far.  Now find an image of a coconut or lime and test the network with this.  What is wrong with using a food image?\n\n\nCreate a new label called \"food\" and add this \nfruit dataset\n, leaving some out of training for testing.  Try your coconut image again.  What if now you tested with a hot dog image?\n\n\n\n\nTransfer Learning with PyTorch\n\n\nHere, for ease of use and speed we'll use Transfer Learning as well.\n\n\n\n\n\n\n\n\n\n\n\n\nTensorFlow\n\n\nEasy:  Run this TensorFlow script to classify a new image (this uses a pretrained Inception V3 model):\n\n\n\n\nhttps://www.tensorflow.org/tutorials/image_recognition\n\n\n\n\nIntermediate: Perform this TensorFlow CNN Tutorial from Google:\n\n\n\n\nhttps://www.tensorflow.org/tutorials/deep_cnn\n\n\n\n\nAdvanced:  Modify this MNIST CNN TensorFlow tutorial for use with the CIFAR-10 dataset:\n\n\n\n\nhttp://adventuresinmachinelearning.com/convolutional-neural-networks-tutorial-tensorflow/\n\n\n\n\nWant More?\n\n\nCheck out Rodrigo Benenson's \nblog\n to find out the best algorithm for classifying with CIFAR-10 and implement it.  May the force be with you.\n\n\nAdditional Help\n\n\n\n\nPyTorch forums - \nRef\n\n\nStackOverflow with \npytorch\n or \ntensorflow\n tag\n\n\nIf using CNTK, you may send your questions to \ncntkhelp@microsoft.com",
            "title": "Practice"
        },
        {
            "location": "/level2/level2_practice/#level-2-challenge",
            "text": "In this intermediate Challenge, you'll apply what you've learned in the edX Deep Learning Explained course, leveraging the Jupyter notebooks you became familiar with in the course.  You'll start exploring the CIFAR-10 dataset along with other datsets in PyTorch and TensorFlow.",
            "title": "Level 2 Challenge"
        },
        {
            "location": "/level2/level2_practice/#adapt-deep-learning-code",
            "text": "",
            "title": "Adapt Deep Learning Code"
        },
        {
            "location": "/level2/level2_practice/#image-classification",
            "text": "Instructions to practice image classification with PyTorch   Get the CIFAR-10 dataset  Run the download script:     Now let's begin working with some code.  Log into the Jupyter  In a code cell  ! git clone ___  Open this notebook:  Modify the notebook to work with the CIFAR-10  Remember you're working with RGB images instead of grayscale    What is the resulting average test error?  Why is this value so different from the MNIST result?  What hyperparameters can you modify to fix this?",
            "title": "Image Classification"
        },
        {
            "location": "/level2/level2_practice/#extra-credit",
            "text": "Go online and find 5 png's of cats and dogs.  Reshape them and pad them to be 32x32 pixels using the Python Pillow library (see  ImageOps ). Test the network with these, following the guidelines and lessons you learned thus far.  Now find an image of a coconut or lime and test the network with this.  What is wrong with using a food image?  Create a new label called \"food\" and add this  fruit dataset , leaving some out of training for testing.  Try your coconut image again.  What if now you tested with a hot dog image?",
            "title": "Extra Credit"
        },
        {
            "location": "/level2/level2_practice/#transfer-learning-with-pytorch",
            "text": "Here, for ease of use and speed we'll use Transfer Learning as well.",
            "title": "Transfer Learning with PyTorch"
        },
        {
            "location": "/level2/level2_practice/#tensorflow",
            "text": "Easy:  Run this TensorFlow script to classify a new image (this uses a pretrained Inception V3 model):   https://www.tensorflow.org/tutorials/image_recognition   Intermediate: Perform this TensorFlow CNN Tutorial from Google:   https://www.tensorflow.org/tutorials/deep_cnn   Advanced:  Modify this MNIST CNN TensorFlow tutorial for use with the CIFAR-10 dataset:   http://adventuresinmachinelearning.com/convolutional-neural-networks-tutorial-tensorflow/",
            "title": "TensorFlow"
        },
        {
            "location": "/level2/level2_practice/#want-more",
            "text": "Check out Rodrigo Benenson's  blog  to find out the best algorithm for classifying with CIFAR-10 and implement it.  May the force be with you.",
            "title": "Want More?"
        },
        {
            "location": "/level2/level2_practice/#additional-help",
            "text": "PyTorch forums -  Ref  StackOverflow with  pytorch  or  tensorflow  tag  If using CNTK, you may send your questions to  cntkhelp@microsoft.com",
            "title": "Additional Help"
        },
        {
            "location": "/level3/level3_setup/",
            "text": "Setup\n\n\nYou'll be doing most things locally in this Advanced Challenge.\n\n\nGetting your Environment Set Up\n\n\nHardware\n\n\nThese are some highly rated suggestions.  You may of course try out the Practice section on a CPU machine.  There's a cloud option below as well.\n\n\nComputer-Laptop\n\n\nAnything with a NVIDIA GTX 1060 (GPU) is good if you travel a lot or cannot necessarily depend on wifi.\n\n\n\n\nE.g.:  \nhttps://www.razerzone.com/gaming-systems/razer-blade-pro\n - plan to get a 1060 w/ 256ssd + 2tb spinner\n\n\nGTX 1080 (extra $2k; only get if this is your primary machine and you travel a lot/have spotty wifi).\n\n\n\n\nComputer-Desktop\n\n\nAny gaming desktop with a min GTX 1080.\u00a0\n\n\n\n\nAlt 1: Custom built.\u00a0 If you go this route -> Add up your GPU ram, multiply by 2 for your min RAM.\u00a0 Get a CPU w/ 48 lanes (so you can go 2 GPUs later).\n\n\nAlt 2: \nhttps://lambdal.com/products/quad\n (this is probably over kill honestly, and your electricity bill might double.\u00a0 Will make a great space heater)\n\n\n\n\nComputer-Remote\n\n\nUse Azure and set up a jupyter notebook.\u00a0 This takes more learning and understanding but is the cheapest getting started option.\n\n\nIt's suggested to provision a new NC-6 (or NC12) DSVM on Ubuntu, updating everything, installing the packages, adding a 1TB data disk and kicking off a password protected Jupyter Notebook in a tmux session.\u00a0 DO NOT put sensitive data on this.\u00a0 It has open ports, admin rights to the system, is password protected only and it's not believed to use SSL unless you set up a certificate.\u00a0 There are other more secure options, though they are more advanced and not covered in this getting started.\n\n\nIoT-Test_Device\n\n\nRaspberry Pi v3, Nvidia TX-1 or Nvidia TX-2.\u00a0 If you are feeling adventurous get a few arduinos as well.\n\n\nSoftware\n\n\n\n\nDocker for Mac or Docker for Windows (avoid Toolbox)\n\n\nAnaconda\n\n\nIf you have a GPU\n\n\nGo to \nCuda Downloads\n\n\nJoin Nvidia Developer program\n\n\nUpdate your GPU drivers\n\n\nInstall Cuda & Cudnn\n\n\n\n\n\n\nInstall your packages\n\n\n\n\nGood Idea:\n\n\n\n\nStackOverflow account",
            "title": "Setup"
        },
        {
            "location": "/level3/level3_setup/#setup",
            "text": "You'll be doing most things locally in this Advanced Challenge.",
            "title": "Setup"
        },
        {
            "location": "/level3/level3_setup/#getting-your-environment-set-up",
            "text": "",
            "title": "Getting your Environment Set Up"
        },
        {
            "location": "/level3/level3_setup/#hardware",
            "text": "These are some highly rated suggestions.  You may of course try out the Practice section on a CPU machine.  There's a cloud option below as well.",
            "title": "Hardware"
        },
        {
            "location": "/level3/level3_setup/#computer-laptop",
            "text": "Anything with a NVIDIA GTX 1060 (GPU) is good if you travel a lot or cannot necessarily depend on wifi.   E.g.:   https://www.razerzone.com/gaming-systems/razer-blade-pro  - plan to get a 1060 w/ 256ssd + 2tb spinner  GTX 1080 (extra $2k; only get if this is your primary machine and you travel a lot/have spotty wifi).",
            "title": "Computer-Laptop"
        },
        {
            "location": "/level3/level3_setup/#computer-desktop",
            "text": "Any gaming desktop with a min GTX 1080.\u00a0   Alt 1: Custom built.\u00a0 If you go this route -> Add up your GPU ram, multiply by 2 for your min RAM.\u00a0 Get a CPU w/ 48 lanes (so you can go 2 GPUs later).  Alt 2:  https://lambdal.com/products/quad  (this is probably over kill honestly, and your electricity bill might double.\u00a0 Will make a great space heater)",
            "title": "Computer-Desktop"
        },
        {
            "location": "/level3/level3_setup/#computer-remote",
            "text": "Use Azure and set up a jupyter notebook.\u00a0 This takes more learning and understanding but is the cheapest getting started option.  It's suggested to provision a new NC-6 (or NC12) DSVM on Ubuntu, updating everything, installing the packages, adding a 1TB data disk and kicking off a password protected Jupyter Notebook in a tmux session.\u00a0 DO NOT put sensitive data on this.\u00a0 It has open ports, admin rights to the system, is password protected only and it's not believed to use SSL unless you set up a certificate.\u00a0 There are other more secure options, though they are more advanced and not covered in this getting started.",
            "title": "Computer-Remote"
        },
        {
            "location": "/level3/level3_setup/#iot-test_device",
            "text": "Raspberry Pi v3, Nvidia TX-1 or Nvidia TX-2.\u00a0 If you are feeling adventurous get a few arduinos as well.",
            "title": "IoT-Test_Device"
        },
        {
            "location": "/level3/level3_setup/#software",
            "text": "Docker for Mac or Docker for Windows (avoid Toolbox)  Anaconda  If you have a GPU  Go to  Cuda Downloads  Join Nvidia Developer program  Update your GPU drivers  Install Cuda & Cudnn    Install your packages   Good Idea:   StackOverflow account",
            "title": "Software"
        },
        {
            "location": "/level3/level3_prep/",
            "text": "Level 3 Preparation\n\n\nYou might find \nthese videos\n from \nthis\n CNN course out of Stanford useful.\n\n\nMore to come.",
            "title": "Preparation"
        },
        {
            "location": "/level3/level3_prep/#level-3-preparation",
            "text": "You might find  these videos  from  this  CNN course out of Stanford useful.  More to come.",
            "title": "Level 3 Preparation"
        },
        {
            "location": "/level3/level3_practice/",
            "text": "Level 3 Challenge\n\n\nIn this advanced Challenge, the instructions will be a little more vague and you'll need to go figure find out much on your own, part of the learning and challenge.\n\n\n\n\nThis problem set is adapted from a Custom ML Resources document written by a colleague.\n\n\n\n\nWhy do this task\n:\u00a0 Usually, beginner tutorials around ML and neural networks begin with classifying hand-written digits from the MNIST dataset.  We are going to begin with something more challenging and much of it will be dealing with data and data formats.  This is to simulate how life will likely be in real life and it's hoped you will learn how to create machine learning models more effectively and quickly in the real world.\u00a0The reason to work through the following is:\n\n\n\n\nIt will force you to read and learn from scratch.\u00a0 You will learn the different label file formats, deserializers and how things compute.\u00a0\n\n\nFor energy/manufacturing you will get .png or .jpg or .tiff files and not stuff already in the perfect format.\u00a0\n\n\nLearning this will hopefully help you understand the concept of \u201cData Packing\u201d.\u00a0\n\n\nThis is not the simplest way, but it forces greater learning.\n\n\n\n\nWorking with PyTorch Locally (VM in cloud ok)\n\n\n\n\n\n\nUnderstand Data Sets\n\n\n\n\n\n\nImage Classification:\n\n\n\n\nStart with a Cifar-10 Jupyter notebook\n\n\nGet Data from here: \nCIFAR-10 data\n\n\nUse the Image deserializer next\n\n\nTry out some data augmentation\n\n\n\n\n\n\nMake sure you also create an example for \ninference\n.\n\n\nUse Scikit-learns\u2019s confusion matrix and classification_report to generate metrics.\n\n\nScikit-learn's confusion matrix\n\n\nScikit-learn's classification report\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWant More?\n\n\n\n\nDo the same exact exercise with CoCo: \nhttp://cocodataset.org/#home\n\n\nWhy do you think you get bad results?\n\n\n\n\n\n\nUse the Out of Box Faster-RCNN solution\n\n\n\n\nTensorFlow\n\n\nTrain a CNN on the CIFAR-10 dataset as in this \nTutorial\n.\n\n\nKey Learnings\n\n\nAdditional Help\n\n\n\n\nPyTorch forums - \nRef\n\n\nStackOverflow with \npytorch\n or \ntensorflow\n tag\n\n\nIf using CNTK, you may send your questions to \ncntkhelp@microsoft.com",
            "title": "Practice"
        },
        {
            "location": "/level3/level3_practice/#level-3-challenge",
            "text": "In this advanced Challenge, the instructions will be a little more vague and you'll need to go figure find out much on your own, part of the learning and challenge.   This problem set is adapted from a Custom ML Resources document written by a colleague.   Why do this task :\u00a0 Usually, beginner tutorials around ML and neural networks begin with classifying hand-written digits from the MNIST dataset.  We are going to begin with something more challenging and much of it will be dealing with data and data formats.  This is to simulate how life will likely be in real life and it's hoped you will learn how to create machine learning models more effectively and quickly in the real world.\u00a0The reason to work through the following is:   It will force you to read and learn from scratch.\u00a0 You will learn the different label file formats, deserializers and how things compute.\u00a0  For energy/manufacturing you will get .png or .jpg or .tiff files and not stuff already in the perfect format.\u00a0  Learning this will hopefully help you understand the concept of \u201cData Packing\u201d.\u00a0  This is not the simplest way, but it forces greater learning.",
            "title": "Level 3 Challenge"
        },
        {
            "location": "/level3/level3_practice/#working-with-pytorch-locally-vm-in-cloud-ok",
            "text": "Understand Data Sets    Image Classification:   Start with a Cifar-10 Jupyter notebook  Get Data from here:  CIFAR-10 data  Use the Image deserializer next  Try out some data augmentation    Make sure you also create an example for  inference .  Use Scikit-learns\u2019s confusion matrix and classification_report to generate metrics.  Scikit-learn's confusion matrix  Scikit-learn's classification report",
            "title": "Working with PyTorch Locally (VM in cloud ok)"
        },
        {
            "location": "/level3/level3_practice/#want-more",
            "text": "Do the same exact exercise with CoCo:  http://cocodataset.org/#home  Why do you think you get bad results?    Use the Out of Box Faster-RCNN solution",
            "title": "Want More?"
        },
        {
            "location": "/level3/level3_practice/#tensorflow",
            "text": "Train a CNN on the CIFAR-10 dataset as in this  Tutorial .",
            "title": "TensorFlow"
        },
        {
            "location": "/level3/level3_practice/#key-learnings",
            "text": "",
            "title": "Key Learnings"
        },
        {
            "location": "/level3/level3_practice/#additional-help",
            "text": "PyTorch forums -  Ref  StackOverflow with  pytorch  or  tensorflow  tag  If using CNTK, you may send your questions to  cntkhelp@microsoft.com",
            "title": "Additional Help"
        }
    ]
}