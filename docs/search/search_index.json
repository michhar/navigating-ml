{
    "docs": [
        {
            "location": "/",
            "text": "navigating-ml\n\n\nWith the advent of more data and compute power, we have a unique opportunity to create more intricate algorithms that help address accuracy issues seen in traditional machine learning.  Deep learning allows us to fine tune the fit of an algorithm to its data in an iterative manner, and to evaluate and \"feed-back\" that information during the training process for a better model.  This results in better models if enough data is provided or in some cases if there's an existing \"base model\", as is the case in transfer learning, if good quality and highly representative data is provided.\n\n\nThat being said, do you feel like there's just too much to be aware of in the ML and Deep Learning space today?  Concepts like Convolutional Neural Networks, GANs, Neural Style Transfer...and networks like AlexNet, ResNet, or Inception...frameworks like CNTK, TensorFlow, Caffe2, PyTorch...extra layers on top of those like TFLearn, Keras, Gluon, MMLSpark...\n\n\n\n\nTip:  Focus on the pipeline or workflow first and iterate on the model after.\n\n\n\n\nIf you suspect you are a beginner in this field, do you need some Python knowledge and fast?  If so go to the Getting Started section to load up on resources and once you're comfortable with data manipulation move on to the Level 1 Challenge for Dealing with Images to start building up your traditional machine learning and neural network cred.\n\n\nDo you grok the basics of ML and perhaps what a fully-connected neural network is?  Have you had some exposure to TensorFlow or CNTK, but don't yet have deep working knowledge of Convolutional Neural Networks?  In that case, try jumping into the Level 2 section of Dealing with Images.  If it seems a little overwhelming, head back to the Level 1 area.  If it's not challenging enough, move on to the Level 3 section.\n\n\nMaybe you're a total neural network geek and you've played with CNTK and TensorFlow a little bit now, gone through several tutorials and maybe built some custom models.  But you haven't set up your environment to include a GPU or two.  Or perhaps you haven't performed image augmentation for input readers in CNTK or created a live REST endpoint and app to call your model?  These are tasks you'll likely encounter once you start working with partners and customers for building custom ML models.  They will want something deployed.  But don't worry, by Level 3 you should be almost there and hopefully hungry for more machine learning knowledge.\n\n\nHere, you'll get exposed to several types, qualities and sizes of datasets.  You'll also use many key Python libraries and general Data Science tools.  These paths can be walked separately or as one big, ML onboarding.  They are intended to help you get up and running for ML partner work quickly and thoroughly.\n\n\nThat being said, feedback is always welcome especially at this early stage.  Please enjoy responsibly.\n\n\nQuick Reference\n\n\nTemplates\n\n\nTDB\n\n\nTools and Technologies\n\n\nIncluded are:\n\n\n\n\nJupyter\n\n\nCustomVision.ai\n\n\nScikit-learn\n\n\nCNTK\n\n\nTensorFlow\n\n\nDeep Learning Virtual Machine\n\n\n\n\nData\n\n\n\n\n\n\n\n\nDataset\n\n\nDescription\n\n\nLink\n\n\n\n\n\n\n\n\n\n\nFashion MNIST Dataset (Source: Kaggle)\n\n\nThe Fashion MNIST dataset is a good one to move on to from the hand-written digits one.  It has 60,000 28x28 training images and 10,000 test images as csv files.\n\n\nLink\n\n\n\n\n\n\nFruit Dataset (FIDS30)\n\n\nThe fruit image data set consists of 971 images of common fruit. The images are classified into 30 different fruit classes.\n\n\nLink\n\n\n\n\n\n\nCIFAR-10 (Source: Kaggle)\n\n\nThe CIFAR-10 data consists of 60,000 32x32 color images in 10 classes, with 6000 images per class. There are 50,000 training images and 10,000 test images in this official data.\n\n\nLink\n\n\n\n\n\n\nCIFAR-10 (Source: Toronto)\n\n\nSame as above\n\n\nLink",
            "title": "Main"
        },
        {
            "location": "/#navigating-ml",
            "text": "With the advent of more data and compute power, we have a unique opportunity to create more intricate algorithms that help address accuracy issues seen in traditional machine learning.  Deep learning allows us to fine tune the fit of an algorithm to its data in an iterative manner, and to evaluate and \"feed-back\" that information during the training process for a better model.  This results in better models if enough data is provided or in some cases if there's an existing \"base model\", as is the case in transfer learning, if good quality and highly representative data is provided.  That being said, do you feel like there's just too much to be aware of in the ML and Deep Learning space today?  Concepts like Convolutional Neural Networks, GANs, Neural Style Transfer...and networks like AlexNet, ResNet, or Inception...frameworks like CNTK, TensorFlow, Caffe2, PyTorch...extra layers on top of those like TFLearn, Keras, Gluon, MMLSpark...   Tip:  Focus on the pipeline or workflow first and iterate on the model after.   If you suspect you are a beginner in this field, do you need some Python knowledge and fast?  If so go to the Getting Started section to load up on resources and once you're comfortable with data manipulation move on to the Level 1 Challenge for Dealing with Images to start building up your traditional machine learning and neural network cred.  Do you grok the basics of ML and perhaps what a fully-connected neural network is?  Have you had some exposure to TensorFlow or CNTK, but don't yet have deep working knowledge of Convolutional Neural Networks?  In that case, try jumping into the Level 2 section of Dealing with Images.  If it seems a little overwhelming, head back to the Level 1 area.  If it's not challenging enough, move on to the Level 3 section.  Maybe you're a total neural network geek and you've played with CNTK and TensorFlow a little bit now, gone through several tutorials and maybe built some custom models.  But you haven't set up your environment to include a GPU or two.  Or perhaps you haven't performed image augmentation for input readers in CNTK or created a live REST endpoint and app to call your model?  These are tasks you'll likely encounter once you start working with partners and customers for building custom ML models.  They will want something deployed.  But don't worry, by Level 3 you should be almost there and hopefully hungry for more machine learning knowledge.  Here, you'll get exposed to several types, qualities and sizes of datasets.  You'll also use many key Python libraries and general Data Science tools.  These paths can be walked separately or as one big, ML onboarding.  They are intended to help you get up and running for ML partner work quickly and thoroughly.  That being said, feedback is always welcome especially at this early stage.  Please enjoy responsibly.",
            "title": "navigating-ml"
        },
        {
            "location": "/#quick-reference",
            "text": "",
            "title": "Quick Reference"
        },
        {
            "location": "/#templates",
            "text": "TDB",
            "title": "Templates"
        },
        {
            "location": "/#tools-and-technologies",
            "text": "Included are:   Jupyter  CustomVision.ai  Scikit-learn  CNTK  TensorFlow  Deep Learning Virtual Machine",
            "title": "Tools and Technologies"
        },
        {
            "location": "/#data",
            "text": "Dataset  Description  Link      Fashion MNIST Dataset (Source: Kaggle)  The Fashion MNIST dataset is a good one to move on to from the hand-written digits one.  It has 60,000 28x28 training images and 10,000 test images as csv files.  Link    Fruit Dataset (FIDS30)  The fruit image data set consists of 971 images of common fruit. The images are classified into 30 different fruit classes.  Link    CIFAR-10 (Source: Kaggle)  The CIFAR-10 data consists of 60,000 32x32 color images in 10 classes, with 6000 images per class. There are 50,000 training images and 10,000 test images in this official data.  Link    CIFAR-10 (Source: Toronto)  Same as above  Link",
            "title": "Data"
        },
        {
            "location": "/python/",
            "text": "Prerequisites\n\n\n\n\nPython 3 (Rocks!)\n\n\n\n\n(2. Algebra, calculus and some basic ML knowledge won't hurt ya)\n\n\nPython\n\n\nJust Starting Out\n\n\nYour first Python course\n\n\nIntro to Python for Data Science from DataCamp\n (Time:  ~4 hours)\n\n\n\n\nPython basics\n\n\nLists\n\n\nFunctions and packages\n\n\nNumpy\n\n\n\n\nLearn about Jupyter\n\n\nNice, short video tour of Jupyter Notebooks\n\n\n\n\nGo to \nAzure Notebooks\n to check out Jupyter notebooks live and try to follow along with the video.\n\n\n\n\nIntermediate\n\n\nPython intro and data sciencey tools - go through in order or skip around\n\n\nPython for Data Science and Intro to Jupyter Notebooks and on Jupyter Notebooks on Azure\n - Note, solutions to exercises are in the last notebook. (Time: ~15 hours)\n\n\n\n\nBasics\n\n\nData Structures\n\n\nFunctional Programming\n\n\nSorting and Pattern Matching\n\n\nObject Oriented Programming\n\n\nBasic Difference from 2 to 3\n\n\nNumerical Computing\n\n\nData Analysis with pandas I\n\n\nData Analysis with pandas II\n\n\nMachine Learning I - ML Basics and Data Exploration\n\n\nMachine Learning II - Supervised and Unsupervised Learning\n\n\nMachine Learning III - Parameter Tuning and Model Evaluation\n\n\nVisualization\n\n\n\n\nA different take on Python and data science (either of these should cover your Python needs)\n\n\nFor a more in-depth Python course, this is a good one on edX out of UC San Diego:  \nPython for Data Science from edX\n.  (Time:  10 weeks/8-10 hours per week)\n\n\n\n\nBasic process of data science\n\n\nPython and Jupyter notebooks\n\n\nAn applied understanding of how to manipulate and analyze uncurated datasets\n\n\nBasic statistical analysis and machine learning methods\n\n\nHow to effectively visualize results\n\n\n\n\nNumerical Python, a.k.a. using the \nnumpy\n package, is essential for the data scientist\n\n\nSee my \npython/numpy.html\n article for a detailed list of \nnumpy\n resources.\n\n\nAdvanced\n\n\nSome books really worth checking out\n\n\nFor a great dive into Python in the context of ML check out this book by Sebastian Raschka (you'll get to write algorithms from scratch in pure Python!): \nPython Machine Learning (2\nnd\n Ed.)\n\n\nNot sure if this book is out yet, but Sebastian Raschka is writing a sequel with more deep learning in Python with TensorFlow: \nIntroduction to Artificial Neural Networks and Deep Learning\n.\n\n\n\"This book is concerned with the nuts and bolts of manipulating, processing, cleaning, and crunching data in Python. My goal is to offer a guide to the parts of the Python programming language and its data-oriented library ecosystem and tools that will equip you to become an effective data analyst. While 'data analysis' is in the title of the book, the focus is specifically on Python programming, libraries, and tools as opposed to data analysis methodology. This is the Python programming you need for data analysis.\"  \nPython for Data Analysis: Data Wrangling with Pandas, NumPy, and IPython by Wes McKinney\n\n\n\"Perhaps you would like to give your homemade robot a brain of its own? Make it recognize faces? Or learn to walk around? Or maybe your company has tons of data (user logs, financial data, production data, machine sensor data, hotline stats, HR reports, etc.), and more than likely you could unearth some hidden gems if you just knew where to look.\" \nHands-On Machine Learning with Scikit-Learn and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems by Aur\u00e9lien G\u00e9ron",
            "title": "Python"
        },
        {
            "location": "/python/#prerequisites",
            "text": "Python 3 (Rocks!)   (2. Algebra, calculus and some basic ML knowledge won't hurt ya)",
            "title": "Prerequisites"
        },
        {
            "location": "/python/#python",
            "text": "",
            "title": "Python"
        },
        {
            "location": "/python/#just-starting-out",
            "text": "Your first Python course  Intro to Python for Data Science from DataCamp  (Time:  ~4 hours)   Python basics  Lists  Functions and packages  Numpy   Learn about Jupyter  Nice, short video tour of Jupyter Notebooks   Go to  Azure Notebooks  to check out Jupyter notebooks live and try to follow along with the video.",
            "title": "Just Starting Out"
        },
        {
            "location": "/python/#intermediate",
            "text": "Python intro and data sciencey tools - go through in order or skip around  Python for Data Science and Intro to Jupyter Notebooks and on Jupyter Notebooks on Azure  - Note, solutions to exercises are in the last notebook. (Time: ~15 hours)   Basics  Data Structures  Functional Programming  Sorting and Pattern Matching  Object Oriented Programming  Basic Difference from 2 to 3  Numerical Computing  Data Analysis with pandas I  Data Analysis with pandas II  Machine Learning I - ML Basics and Data Exploration  Machine Learning II - Supervised and Unsupervised Learning  Machine Learning III - Parameter Tuning and Model Evaluation  Visualization   A different take on Python and data science (either of these should cover your Python needs)  For a more in-depth Python course, this is a good one on edX out of UC San Diego:   Python for Data Science from edX .  (Time:  10 weeks/8-10 hours per week)   Basic process of data science  Python and Jupyter notebooks  An applied understanding of how to manipulate and analyze uncurated datasets  Basic statistical analysis and machine learning methods  How to effectively visualize results",
            "title": "Intermediate"
        },
        {
            "location": "/python/#numerical-python-aka-using-the-numpy-package-is-essential-for-the-data-scientist",
            "text": "See my  python/numpy.html  article for a detailed list of  numpy  resources.",
            "title": "Numerical Python, a.k.a. using the numpy package, is essential for the data scientist"
        },
        {
            "location": "/python/#advanced",
            "text": "Some books really worth checking out  For a great dive into Python in the context of ML check out this book by Sebastian Raschka (you'll get to write algorithms from scratch in pure Python!):  Python Machine Learning (2 nd  Ed.)  Not sure if this book is out yet, but Sebastian Raschka is writing a sequel with more deep learning in Python with TensorFlow:  Introduction to Artificial Neural Networks and Deep Learning .  \"This book is concerned with the nuts and bolts of manipulating, processing, cleaning, and crunching data in Python. My goal is to offer a guide to the parts of the Python programming language and its data-oriented library ecosystem and tools that will equip you to become an effective data analyst. While 'data analysis' is in the title of the book, the focus is specifically on Python programming, libraries, and tools as opposed to data analysis methodology. This is the Python programming you need for data analysis.\"   Python for Data Analysis: Data Wrangling with Pandas, NumPy, and IPython by Wes McKinney  \"Perhaps you would like to give your homemade robot a brain of its own? Make it recognize faces? Or learn to walk around? Or maybe your company has tons of data (user logs, financial data, production data, machine sensor data, hotline stats, HR reports, etc.), and more than likely you could unearth some hidden gems if you just knew where to look.\"  Hands-On Machine Learning with Scikit-Learn and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems by Aur\u00e9lien G\u00e9ron",
            "title": "Advanced"
        },
        {
            "location": "/python/numpy/",
            "text": "A List of \nnumpy\n resources\n\n\nNumPy stands for Numerical Python.  It's widely used in Linear Algebra applications and has become a \nde facto\n library for use in Machine Learning.  It uses memory efficiently and is mostly implemented in C, thus is a very efficient option for numerical calculations (see more in Reference #3 by Sebastian Raschka).  I've made a list of resources for the \nnumpy\n library to help someone new or someone in need of a good reference later on.  It was created by Travis Oliphant in 2005 (also the creator of SciPy).  The package lives on GitHub (\nLink\n).\n\n\nListing.  In no special order.\n\n\n\n\nQuickstart tutorial.  From the \nscipy\n docs.  Short, but good starting point. \nRef\n\n\nIntroduction to NumPy.  A nice whole chapter on \nnumpy\n by Jake VanderPlas. \nRef\n\n\nIntroduction to Numpy.  A really nice quick tour as an appendix to a deep learning book by Sebastian Raschka \nRef\n and as a \nNotebook\n\n\nNumerical Scientific Computing.  Quick tour with exercises by Micheleen Harris.  \nNotebook\n\n\nNumPy Practice.  With some nice notes on Linear Algebra operations in \nnumpy\n by Tirthajyoti Sarkar.  \nNotebook\n\n\n\n\nA listing of Linear Algebra resources to go along with this\n\n\n\n\nStanford comprehensive Linear Algebra review document by Zico Kolter.  \nRef\n\n\n\n\nLinear Algebra Review (Andrew Ng).\n\n\n\n\nMatrices and Vectors. \nVideo\n\n\nAddition And Scalar Multiplication. \nVideo\n\n\nMatrix Vector Multiplication.  \nVideo\n\n\nMatrix-Matrix Multiplication.  \nVideo\n\n\nMatrix Multiplication Properties.  \nVideo\n\n\nInverse And Transpose.  \nVideo\n\n\n\n\n\n\n\n\nLinear Algebra youtube channel by Khan Academy \nVideos\n\n\n\n\nCoding the Matrix.  \nBook\n\n\n\n\nExercise:  Follow along with these courses by doing things concurrently in \nnumpy\n.\n\n\nThere are likely many more great resources out there so feel free to create an issue on this \nGitHub repo\n letting me know about yours or others.",
            "title": "NumPy and Linear Algebra"
        },
        {
            "location": "/python/numpy/#a-list-of-numpy-resources",
            "text": "NumPy stands for Numerical Python.  It's widely used in Linear Algebra applications and has become a  de facto  library for use in Machine Learning.  It uses memory efficiently and is mostly implemented in C, thus is a very efficient option for numerical calculations (see more in Reference #3 by Sebastian Raschka).  I've made a list of resources for the  numpy  library to help someone new or someone in need of a good reference later on.  It was created by Travis Oliphant in 2005 (also the creator of SciPy).  The package lives on GitHub ( Link ).",
            "title": "A List of numpy resources"
        },
        {
            "location": "/python/numpy/#listing-in-no-special-order",
            "text": "Quickstart tutorial.  From the  scipy  docs.  Short, but good starting point.  Ref  Introduction to NumPy.  A nice whole chapter on  numpy  by Jake VanderPlas.  Ref  Introduction to Numpy.  A really nice quick tour as an appendix to a deep learning book by Sebastian Raschka  Ref  and as a  Notebook  Numerical Scientific Computing.  Quick tour with exercises by Micheleen Harris.   Notebook  NumPy Practice.  With some nice notes on Linear Algebra operations in  numpy  by Tirthajyoti Sarkar.   Notebook",
            "title": "Listing.  In no special order."
        },
        {
            "location": "/python/numpy/#a-listing-of-linear-algebra-resources-to-go-along-with-this",
            "text": "Stanford comprehensive Linear Algebra review document by Zico Kolter.   Ref   Linear Algebra Review (Andrew Ng).   Matrices and Vectors.  Video  Addition And Scalar Multiplication.  Video  Matrix Vector Multiplication.   Video  Matrix-Matrix Multiplication.   Video  Matrix Multiplication Properties.   Video  Inverse And Transpose.   Video     Linear Algebra youtube channel by Khan Academy  Videos   Coding the Matrix.   Book   Exercise:  Follow along with these courses by doing things concurrently in  numpy .  There are likely many more great resources out there so feel free to create an issue on this  GitHub repo  letting me know about yours or others.",
            "title": "A listing of Linear Algebra resources to go along with this"
        },
        {
            "location": "/python/nlp/",
            "text": "Natural Language Processing Resources\n\n\nTutorials\n\n\n\n\nGensim official Docs \nTutorial\n\n\nNatural Language Processing with NLTK and Gensim \nVideo\n\n\nA Word2Vec Keras tutorial \nTutorial\n\n\nLanguage Understanding with Recurrent Networks and CNTK \nTutorial\n\n\nVector Representations of Words with TensorFlow \nTutorial\n\n\nWord2Vec word embedding tutorial in Python and TensorFlow \nTutorial\n\n\n\n\nExercises\n\n\n\n\n\n\n\n\nTopic\n\n\nTitle/Description\n\n\nLink\n\n\n\n\n\n\n\n\n\n\nSentiment Analysis\n\n\nBuild a sentiment analysis / polarity model \nscikit-learn\n\n\nExercise\n and \nCode to start\n\n\n\n\n\n\n\n\nCourses and Course Materials\n\n\n\n\nStanford Deep Learning for NLP (cs224n) \nCourse Material\n\n\n\n\nExamples\n\n\n\n\nDocument clustering with k-means official \nscikit-learn\n \nExample\n\n\nFeaturize free-form text data using \nmmlspark\n on top of primitives in SparkML via a single transformer in this official \nmmlspark\n \nNotebook\n\n\nSequence Classification with CNTK \nExample\n\n\nSequence2Sequence with CNTK \nExample\n\n\n\n\nNLP-Specific Packages\n\n\n\n\nallennlp\n:  Deep Learning for NLP from AllenNLP built on PyTorch \nRef\n - good for conditional random field, encoders/decoders, reading comprehension, semantic role, etc.\n\n\ngensim\n:  topic modelling \nDocs\n - good for word2vec, semantic similarity, LDA, LSA, etc.\n\n\nnltk\n:  Natural Language Toolkit \nDocs\n - good for tokenization, stemming, tagging, parsing, corpora, etc.\n\n\nspacy\n:  Efficient and Backed by ANNs NLP Toolkit \nDocs\n - good for parsing, tagging, entity recognition, text categorization, phrase matching, etc.\n\n\n\n\nKaggle\n\n\n\n\nToxic Comment Classification Challenge \nCompetition\n\n\n\n\nBooks\n\n\nTBD\n\n\nBlog Articles\n\n\n\n\n\n\n\n\nTopic\n\n\nTitle/Description\n\n\nLink\n\n\n\n\n\n\n\n\n\n\nBasics\n\n\n7 types of Artificial Neural Networks for Natural Language Processing\n\n\nLink\n\n\n\n\n\n\nTF/IDF\n\n\nCalculating TF/IDF on How I met your mother transcripts (with \nscikit-learn\n)\n\n\nLink\n\n\n\n\n\n\nGeneral/Sentiment Analysis\n\n\nBreakthrough Research Papers and Models for Sentiment Analysis\n\n\nLink\n\n\n\n\n\n\nSequence to Sequence\n\n\nA tutorial on how to summarize text and generate features from Github Issues using deep learning with Keras and TensorFlow.\n\n\nLink\n\n\n\n\n\n\n\n\n\n\nLink\n\n\n\n\n\n\n\n\nPapers\n\n\n\n\n\n\n\n\nTopic\n\n\nTitle/Description\n\n\nAuthor(s)\n\n\nLink\n\n\n\n\n\n\n\n\n\n\nText Classification\n\n\nFine-tuned Language Models for Text Classification (with Transfer Learning)\n\n\nJeremy Howard, Sebastian Ruder\n\n\nLink\n\n\n\n\n\n\n\n\nNLP at Scale\n\n\n\n\nDocument classification with \npyspark\n with HDInsight on Azure \nDoc\n\n\n\n\nList updated 2017-01-26",
            "title": "Natural Language Processing Resources"
        },
        {
            "location": "/python/nlp/#natural-language-processing-resources",
            "text": "",
            "title": "Natural Language Processing Resources"
        },
        {
            "location": "/python/nlp/#tutorials",
            "text": "Gensim official Docs  Tutorial  Natural Language Processing with NLTK and Gensim  Video  A Word2Vec Keras tutorial  Tutorial  Language Understanding with Recurrent Networks and CNTK  Tutorial  Vector Representations of Words with TensorFlow  Tutorial  Word2Vec word embedding tutorial in Python and TensorFlow  Tutorial",
            "title": "Tutorials"
        },
        {
            "location": "/python/nlp/#exercises",
            "text": "Topic  Title/Description  Link      Sentiment Analysis  Build a sentiment analysis / polarity model  scikit-learn  Exercise  and  Code to start",
            "title": "Exercises"
        },
        {
            "location": "/python/nlp/#courses-and-course-materials",
            "text": "Stanford Deep Learning for NLP (cs224n)  Course Material",
            "title": "Courses and Course Materials"
        },
        {
            "location": "/python/nlp/#examples",
            "text": "Document clustering with k-means official  scikit-learn   Example  Featurize free-form text data using  mmlspark  on top of primitives in SparkML via a single transformer in this official  mmlspark   Notebook  Sequence Classification with CNTK  Example  Sequence2Sequence with CNTK  Example",
            "title": "Examples"
        },
        {
            "location": "/python/nlp/#nlp-specific-packages",
            "text": "allennlp :  Deep Learning for NLP from AllenNLP built on PyTorch  Ref  - good for conditional random field, encoders/decoders, reading comprehension, semantic role, etc.  gensim :  topic modelling  Docs  - good for word2vec, semantic similarity, LDA, LSA, etc.  nltk :  Natural Language Toolkit  Docs  - good for tokenization, stemming, tagging, parsing, corpora, etc.  spacy :  Efficient and Backed by ANNs NLP Toolkit  Docs  - good for parsing, tagging, entity recognition, text categorization, phrase matching, etc.",
            "title": "NLP-Specific Packages"
        },
        {
            "location": "/python/nlp/#kaggle",
            "text": "Toxic Comment Classification Challenge  Competition",
            "title": "Kaggle"
        },
        {
            "location": "/python/nlp/#books",
            "text": "TBD",
            "title": "Books"
        },
        {
            "location": "/python/nlp/#blog-articles",
            "text": "Topic  Title/Description  Link      Basics  7 types of Artificial Neural Networks for Natural Language Processing  Link    TF/IDF  Calculating TF/IDF on How I met your mother transcripts (with  scikit-learn )  Link    General/Sentiment Analysis  Breakthrough Research Papers and Models for Sentiment Analysis  Link    Sequence to Sequence  A tutorial on how to summarize text and generate features from Github Issues using deep learning with Keras and TensorFlow.  Link      Link",
            "title": "Blog Articles"
        },
        {
            "location": "/python/nlp/#papers",
            "text": "Topic  Title/Description  Author(s)  Link      Text Classification  Fine-tuned Language Models for Text Classification (with Transfer Learning)  Jeremy Howard, Sebastian Ruder  Link",
            "title": "Papers"
        },
        {
            "location": "/python/nlp/#nlp-at-scale",
            "text": "Document classification with  pyspark  with HDInsight on Azure  Doc   List updated 2017-01-26",
            "title": "NLP at Scale"
        },
        {
            "location": "/level1/level1_setup/",
            "text": "Setup\n\n\n\n\n\n\nAnaconda3 Python (Recommended versions:  Anaconda3 4.1.1 for Python 3.5.2 recommended, Anaconda3 4.3.1 for Python 3.6 ok, too)\n\n\n\n\nThis will allow you to create \nconda\n environments to \"contain\" your projects and Python versions.  In fact you can use your current Anaconda or Miniconda Python to install other Python versions from the command line \nRef\n\n\n\n\n\n\n\n\nJupyter notebook with Python and ML ecosystem (local, service or cloud)\n\n\n\n\nFor the first part of the Beginner Challenge, you can use \nAzure Notebooks\n service as your Python environment as it's a Jupyter notebook system and free.  Or you can set up Jupyter notebooks locally with the ML ecosystem (\nnumpy\n, \npandas\n, \nscikit-learn\n, \nopencv-python\n etc.).\n\n\nMore on Jupyter from their \nDocs\n.\n\n\n\n\n\n\n\n\n\n\nThis is a good chance to build up some Data Science tools locally - nice (from experience) when you have spotty wifi.\n\n\n\n\n\n\nDocker for Mac or Docker for Windows (avoid Toolbox)\n\n\nThis is to aid in creating reproducible setups so you can share with others so they can do it, too!\n\n\n\n\n\n\n\n\nGood Idea:\n\n\n\n\nStackOverflow account\n\n\n\n\nAdditional Resources\n\n\n\n\nThe Stats/ML StackExchange is a useful place to pose questions about ML and stats \nLink",
            "title": "Setup"
        },
        {
            "location": "/level1/level1_setup/#setup",
            "text": "Anaconda3 Python (Recommended versions:  Anaconda3 4.1.1 for Python 3.5.2 recommended, Anaconda3 4.3.1 for Python 3.6 ok, too)   This will allow you to create  conda  environments to \"contain\" your projects and Python versions.  In fact you can use your current Anaconda or Miniconda Python to install other Python versions from the command line  Ref     Jupyter notebook with Python and ML ecosystem (local, service or cloud)   For the first part of the Beginner Challenge, you can use  Azure Notebooks  service as your Python environment as it's a Jupyter notebook system and free.  Or you can set up Jupyter notebooks locally with the ML ecosystem ( numpy ,  pandas ,  scikit-learn ,  opencv-python  etc.).  More on Jupyter from their  Docs .      This is a good chance to build up some Data Science tools locally - nice (from experience) when you have spotty wifi.    Docker for Mac or Docker for Windows (avoid Toolbox)  This is to aid in creating reproducible setups so you can share with others so they can do it, too!",
            "title": "Setup"
        },
        {
            "location": "/level1/level1_setup/#good-idea",
            "text": "StackOverflow account",
            "title": "Good Idea:"
        },
        {
            "location": "/level1/level1_setup/#additional-resources",
            "text": "The Stats/ML StackExchange is a useful place to pose questions about ML and stats  Link",
            "title": "Additional Resources"
        },
        {
            "location": "/level1/level1_prep/",
            "text": "Level 1 Preparation\n\n\nTo begin at this level you should have:\n\n\n\n\nFamiliarity with Python 3 for general purpose programming.  See the \nPython\n section for more.\n\n\nWorking knowledge of traditional ML (when to use what)\n\n\nBasic data mining skills\n\n\n\n\nConcepts\n\n\nDealing with Image Data\n\n\n\n\nRead through this excellent first taste of Image Classification from this Stanford CS231n course \nRef\n\n\n\n\nNeural Networks\n\n\n\n\nRead through \nthis\n excellent explanation of a single-layer neural network.  This information will lay the foundation for these sets of challenges and help you get started from the ground-up, quickly with key concepts and Python code snippets.\n\n\n\n\nTools\n\n\n\n\nGit and GitHub for version control.\n\n\nJupyter notebook skills. \nChapter 1 Python Data Science Handbook\n\n\nGet a good grasp of Python for data tasks:\n\n\nHow to read data (matplotlib, Pillow/PIL, opencv)\n\n\nHow to manipulate data (numpy, pandas, scikit-learn) \n\n\nHow to plot data (matplotlib, plotly)\n\n\nTraditional ML (scikit-learn)\n\n\n\n\n\n\n\n\nA Learning Path is under dev to cover the above topics in linear fashion\n\n\nAdditional Resources\n\n\nScikit-Learn\n\n\nExcellent 3-hr scikit-learn tutorials from PyCon 2015:\n\n\n\n\nWatch \nthis\n scikit-learn tutorial by Jake VanderPlas (Part 1) and \nthe next\n tutorial by Olivier Grisel (Part 2).\n\n\n\n\nLearn about ML and Python scikit-learn in this \nvideo series",
            "title": "Preparation"
        },
        {
            "location": "/level1/level1_prep/#level-1-preparation",
            "text": "To begin at this level you should have:   Familiarity with Python 3 for general purpose programming.  See the  Python  section for more.  Working knowledge of traditional ML (when to use what)  Basic data mining skills",
            "title": "Level 1 Preparation"
        },
        {
            "location": "/level1/level1_prep/#concepts",
            "text": "",
            "title": "Concepts"
        },
        {
            "location": "/level1/level1_prep/#dealing-with-image-data",
            "text": "Read through this excellent first taste of Image Classification from this Stanford CS231n course  Ref",
            "title": "Dealing with Image Data"
        },
        {
            "location": "/level1/level1_prep/#neural-networks",
            "text": "Read through  this  excellent explanation of a single-layer neural network.  This information will lay the foundation for these sets of challenges and help you get started from the ground-up, quickly with key concepts and Python code snippets.",
            "title": "Neural Networks"
        },
        {
            "location": "/level1/level1_prep/#tools",
            "text": "Git and GitHub for version control.  Jupyter notebook skills.  Chapter 1 Python Data Science Handbook  Get a good grasp of Python for data tasks:  How to read data (matplotlib, Pillow/PIL, opencv)  How to manipulate data (numpy, pandas, scikit-learn)   How to plot data (matplotlib, plotly)  Traditional ML (scikit-learn)     A Learning Path is under dev to cover the above topics in linear fashion",
            "title": "Tools"
        },
        {
            "location": "/level1/level1_prep/#additional-resources",
            "text": "",
            "title": "Additional Resources"
        },
        {
            "location": "/level1/level1_prep/#scikit-learn",
            "text": "Excellent 3-hr scikit-learn tutorials from PyCon 2015:   Watch  this  scikit-learn tutorial by Jake VanderPlas (Part 1) and  the next  tutorial by Olivier Grisel (Part 2).   Learn about ML and Python scikit-learn in this  video series",
            "title": "Scikit-Learn"
        },
        {
            "location": "/level1/level1_practice/",
            "text": "Level 1 Challenge\n\n\nIt is recommended that you have completed the \nLeve 1 Preparation\n.\n\n\nIn this Beginner Challenge you'll learn about basic ML and neural networks hands-on with Jupyter notebooks and Python.  You'll be introduced to scikit-learn, CNTK, and TensorFlow as Python packages commonly used in data manipulation and data science.  \n\n\nHere and throughout these practice exercises you'll work with the following image datasets: the fruit FIDS30 dataset, the Kaggle Fashion MNIST dataset and the CIFAR-10 (tiny images) dataset.\n\n\nCustom Vision (Microsoft)\n\n\nDownload the \nfruit dataset\n and build a fruit image classifier with two fruit classes using \nhttps://customvision.ai/\n.\n\n\nAfter you have done some training above, create a Python script to \"pixel-normalize\" the images prior to training the model and retrain to see your new Precision and Recall.\n\n\n\n\n\n\nSome defintions.  \nPrecision\n:  if a tag is precicted by your classifier, how likely is it that it is right?  \nRecall\n:  out of the tags that should be classified as right, what percentage did your classifier correctly find?\n\n\n\n\nFirst Custom ML (Open Source Tools)\n\n\nFor these two problems, it is recommended to go through the code from the original source line by line in whatever fashion you see fit so that you really understand what is happening.\n\n\n\n\nTIPS:  Place all imports at the top of the notebook.  Call the training data something consistent thoughout all of your work (X_train -> training data, y_train -> labels, X_test -> test data...).\n\n\n\n\nImage Classification\n\n\nCreate a Python program to classify images from Fashion MNIST Dataset (get \nhere\n) leveraging code samples from the Python Data Science Handbook - \nRef\n.  Refer to Chapter 2 and 3 of this Handbook for information on data manipulation in Python if not already familiar.\n\n\nDo this in a Jupyter notebook (any service or locally) - recall you learned about this tool the \nSetup Section\n.  \n\n\nIt might help to examine the existing data format for \nsklearn.datasets.load_digits\n so that you can convert into that format to utilize the algorithms in \nsklearn\n (scikit-learn).  \n\n\n\n\nWhat did you find?  Which fashion item has the best accuracy, which the worst?  Why do you think that is?  Is there a way you could imagine improving this model?\n\n\nTry a different model\n\n\nScale the images (in \nsklearn\n) and check the accuracy of the model again.  Did it improve or worsen?\n\n\n\n\nObject Detection\n\n\n\n\nIn the real world, data is rarely so uniform and simple pixels will not be suitable: this has led to a large literature on feature extraction methods for image data.\n\n\n\n\nCreate a Python program to detect cats in 2D images by leveraging code samples from the Python Data Science Handbook - \nRef\n.  Refer to Chapter 2 and 3 of this Handbook for information on data manipulation in Python if not already familiar.\n\n\nDo this in a Jupyter notebook (any service or locally) - recall you learned about this tool the \nSetup Section\n.  \n\n\nIt might help to examine the existing data format for \nsklearn.datasets.fetch_lfw_people\n so that you can convert into that format to utilize the algorithms in \nsklearn\n (scikit-learn) to create this detector.  \n\n\n\n\nWhat other confounding factors are there for images other than illumination, you think?\n\n\nPlot the original image along with the \nskimage.rgb2gray\n version and the HOG representation.  See how this works in \nmatplotlib\n.  What does \nskimage.rgb2gray\n actually do?\n\n\nCan you scale the new image of the astronaut with the \nPIL\n module instead?  This module is very powerful and good to know about (as well as \nopencv\n)?\n\n\nTry out the model on the entire test image instead.  What do you find out?\n\n\nTry using sliding windows with a variety of sizes (aspect ratios).  What do you find out?\n\n\nRead in a new image that contains a face and on one that does not and try your model on that.\n\n\nAugment the data to expand the training and test datasets (e.g. use a library like \nimgaug\n) and retrain and test.\n\n\nExtra credit\n:  Implement Non-Maximum Suppression in Python to find the single best bounding box of a group of bounding boxes as are found above.  Apply this to the astronaut image.\n\n\n\n\nBasic Neural Nets\n\n\nThe purpose of the Basic Neural Nets exercises are to familiarize you with how a simple artificial neuron works and then set of a few neurons to form a network (artificial neural network) - all from the ground-up - this knowledge will serve you well.  It will really get to the core of neural nets and give you a perfect \"from scratch\" introduction (the code template already exists around the infamous iris dataset, you'll just make it work with some fashionable images).  If we want to get to know deep neural nets, why not dive in deep to start!\n\n\n\n\nUse \nAzure Notebooks\n for this tutorial.  Fire up a blank Python 3.5 Jupyter notebook for this.\n\n\nGet the following sample image dataset loaded in your Jupyter notebook: \ntrain and test Fashion MNIST Dataset (Source: Kaggle)\n\n\nAdapt a from-scratch Perceptron as in this \nJupyter notebook\n to train and test on the image dataset.\n\n\nUse the URL option when opening up a new notebook in Azure Notebooks\n\n\nOr, download by right clicking on \"Raw\" and \"Save link as...\"\n\n\nRe-implement the Perceptron with \nsklearn\n (scikit-learn)\n\n\n\n\n\n\nAdapt a from-scratch Multilayer Perceptron (MLP) as in this \nJupyter notebook\n\n\nUse the URL option when opening up a new notebook in Azure Notebooks\n\n\nOr, download by right clicking on \"Raw\" and \"Save link as...\"\n\n\nRe-implement the MLP with \nsklearn\n\n\n\n\n\n\n\n\nMoving On\n\n\nNow it is time to move on to Level 2 Preparation.\n\n\nAdditional Help\n\n\n\n\nStackOverflow with \nsklearn\n, \njupyter\n\n\nFor Custom Vision you can email \ncustomvisionteam@microsoft.com\n.",
            "title": "Practice"
        },
        {
            "location": "/level1/level1_practice/#level-1-challenge",
            "text": "It is recommended that you have completed the  Leve 1 Preparation .  In this Beginner Challenge you'll learn about basic ML and neural networks hands-on with Jupyter notebooks and Python.  You'll be introduced to scikit-learn, CNTK, and TensorFlow as Python packages commonly used in data manipulation and data science.    Here and throughout these practice exercises you'll work with the following image datasets: the fruit FIDS30 dataset, the Kaggle Fashion MNIST dataset and the CIFAR-10 (tiny images) dataset.",
            "title": "Level 1 Challenge"
        },
        {
            "location": "/level1/level1_practice/#custom-vision-microsoft",
            "text": "Download the  fruit dataset  and build a fruit image classifier with two fruit classes using  https://customvision.ai/ .  After you have done some training above, create a Python script to \"pixel-normalize\" the images prior to training the model and retrain to see your new Precision and Recall.    Some defintions.   Precision :  if a tag is precicted by your classifier, how likely is it that it is right?   Recall :  out of the tags that should be classified as right, what percentage did your classifier correctly find?",
            "title": "Custom Vision (Microsoft)"
        },
        {
            "location": "/level1/level1_practice/#first-custom-ml-open-source-tools",
            "text": "For these two problems, it is recommended to go through the code from the original source line by line in whatever fashion you see fit so that you really understand what is happening.   TIPS:  Place all imports at the top of the notebook.  Call the training data something consistent thoughout all of your work (X_train -> training data, y_train -> labels, X_test -> test data...).",
            "title": "First Custom ML (Open Source Tools)"
        },
        {
            "location": "/level1/level1_practice/#image-classification",
            "text": "Create a Python program to classify images from Fashion MNIST Dataset (get  here ) leveraging code samples from the Python Data Science Handbook -  Ref .  Refer to Chapter 2 and 3 of this Handbook for information on data manipulation in Python if not already familiar.  Do this in a Jupyter notebook (any service or locally) - recall you learned about this tool the  Setup Section .    It might help to examine the existing data format for  sklearn.datasets.load_digits  so that you can convert into that format to utilize the algorithms in  sklearn  (scikit-learn).     What did you find?  Which fashion item has the best accuracy, which the worst?  Why do you think that is?  Is there a way you could imagine improving this model?  Try a different model  Scale the images (in  sklearn ) and check the accuracy of the model again.  Did it improve or worsen?",
            "title": "Image Classification"
        },
        {
            "location": "/level1/level1_practice/#object-detection",
            "text": "In the real world, data is rarely so uniform and simple pixels will not be suitable: this has led to a large literature on feature extraction methods for image data.   Create a Python program to detect cats in 2D images by leveraging code samples from the Python Data Science Handbook -  Ref .  Refer to Chapter 2 and 3 of this Handbook for information on data manipulation in Python if not already familiar.  Do this in a Jupyter notebook (any service or locally) - recall you learned about this tool the  Setup Section .    It might help to examine the existing data format for  sklearn.datasets.fetch_lfw_people  so that you can convert into that format to utilize the algorithms in  sklearn  (scikit-learn) to create this detector.     What other confounding factors are there for images other than illumination, you think?  Plot the original image along with the  skimage.rgb2gray  version and the HOG representation.  See how this works in  matplotlib .  What does  skimage.rgb2gray  actually do?  Can you scale the new image of the astronaut with the  PIL  module instead?  This module is very powerful and good to know about (as well as  opencv )?  Try out the model on the entire test image instead.  What do you find out?  Try using sliding windows with a variety of sizes (aspect ratios).  What do you find out?  Read in a new image that contains a face and on one that does not and try your model on that.  Augment the data to expand the training and test datasets (e.g. use a library like  imgaug ) and retrain and test.  Extra credit :  Implement Non-Maximum Suppression in Python to find the single best bounding box of a group of bounding boxes as are found above.  Apply this to the astronaut image.",
            "title": "Object Detection"
        },
        {
            "location": "/level1/level1_practice/#basic-neural-nets",
            "text": "The purpose of the Basic Neural Nets exercises are to familiarize you with how a simple artificial neuron works and then set of a few neurons to form a network (artificial neural network) - all from the ground-up - this knowledge will serve you well.  It will really get to the core of neural nets and give you a perfect \"from scratch\" introduction (the code template already exists around the infamous iris dataset, you'll just make it work with some fashionable images).  If we want to get to know deep neural nets, why not dive in deep to start!   Use  Azure Notebooks  for this tutorial.  Fire up a blank Python 3.5 Jupyter notebook for this.  Get the following sample image dataset loaded in your Jupyter notebook:  train and test Fashion MNIST Dataset (Source: Kaggle)  Adapt a from-scratch Perceptron as in this  Jupyter notebook  to train and test on the image dataset.  Use the URL option when opening up a new notebook in Azure Notebooks  Or, download by right clicking on \"Raw\" and \"Save link as...\"  Re-implement the Perceptron with  sklearn  (scikit-learn)    Adapt a from-scratch Multilayer Perceptron (MLP) as in this  Jupyter notebook  Use the URL option when opening up a new notebook in Azure Notebooks  Or, download by right clicking on \"Raw\" and \"Save link as...\"  Re-implement the MLP with  sklearn",
            "title": "Basic Neural Nets"
        },
        {
            "location": "/level1/level1_practice/#moving-on",
            "text": "Now it is time to move on to Level 2 Preparation.",
            "title": "Moving On"
        },
        {
            "location": "/level1/level1_practice/#additional-help",
            "text": "StackOverflow with  sklearn ,  jupyter  For Custom Vision you can email  customvisionteam@microsoft.com .",
            "title": "Additional Help"
        },
        {
            "location": "/level2/level2_setup/",
            "text": "Setup\n\n\n\n\n\n\n(Deploy when ready if you don't have it yet) \nLinux (Ubuntu) Deep Learning Virtual Machine\n Standard NC6\n\n\n\n\nTip: place everything for this set of challenges in the same resource group to tear down together at the end.\n\n\n\n\n\n\n\n\nEnsure Jupyter notebooks are working.\n\n\n\n\n\"access the Jupyter notebook server from any host. Just navigate in the browser to \nhttps://<VM DNS name or IP Address>:8000/\n\" (\nDoc\n - check out \"Jupyter notebook\" for more)\n\n\n\n\n\n\n\n\nDownload Azure Machine Learning Workbench locally from this \nDoc\n.\n\n\n\n\n\n\n\n\nPlan to work with CNTK locally?  Make sure you check out which versions of Python it works with and note it's for Windows and Ubuntu-flavored Linux as of now.  If you are on a different OS there's a Docker image that is easy to set up and begin right away with CNTK.\n\n\n\n\n\n\nCNTK Install - \nDocs\n\n\n\n\n\n\nTensorFlow can be found on all Linux and Windows Data Science Virtual Machines and Deep Learning Virtual Machines along with a long list of common data science tools - see \nDocs",
            "title": "Setup"
        },
        {
            "location": "/level2/level2_setup/#setup",
            "text": "(Deploy when ready if you don't have it yet)  Linux (Ubuntu) Deep Learning Virtual Machine  Standard NC6   Tip: place everything for this set of challenges in the same resource group to tear down together at the end.     Ensure Jupyter notebooks are working.   \"access the Jupyter notebook server from any host. Just navigate in the browser to  https://<VM DNS name or IP Address>:8000/ \" ( Doc  - check out \"Jupyter notebook\" for more)     Download Azure Machine Learning Workbench locally from this  Doc .     Plan to work with CNTK locally?  Make sure you check out which versions of Python it works with and note it's for Windows and Ubuntu-flavored Linux as of now.  If you are on a different OS there's a Docker image that is easy to set up and begin right away with CNTK.    CNTK Install -  Docs    TensorFlow can be found on all Linux and Windows Data Science Virtual Machines and Deep Learning Virtual Machines along with a long list of common data science tools - see  Docs",
            "title": "Setup"
        },
        {
            "location": "/level2/level2_prep/",
            "text": "Level 2 Preparation\n\n\nNow it's time to really learn about CNTK and classifiers such as logistic regression, multilayer perceptron, and convolutional network (CNN/ConvNet) classifiers.  The MNIST hand-written digits dataset is used in the following course to classify grey-scale images of digits.  We'll use this code in our Challenge section so go ahead and get familiar with it now by taking this course.\n\n\nWork through the first four modules of the free Deep Learning Explained edX \ncourse\n.  Each module should take 1-2 hours each.\n\n\n\n\nLearn concepts around neural networks for image applications.\n\n\nList the differences between a Convolutional (ConvNet/CNN) and regular Dense Neural Network.\n\n\nList and give examples of the tunable hyperparameters one can find in a ConvNet.\n...\n\n\n\n\n\n\n\n\nFor Quick Reference - MNIST Digits and CNTK Notebooks and Videos\n\n\nBelow are links to some of the Jupyter notebooks used in the edX Deep Learning Explained course (linked to above) using the MNIST hand-written digits dataset.  Included are links to accompanying videos by Microsoft data scientists around this example.\n\n\nThey are meant to be worked on in order, each tutorial building on the previous.  Ideally, you will have also watched the accompanying lectures from the course.\n\n\n\n\n\n\n\n\nTopic\n\n\nTutorial on Jupyter\n\n\nVideo Link\n\n\n\n\n\n\n\n\n\n\nLoading MNIST data\n\n\nNotebook 103A on CNTK GitHub\n\n\nVideo\n\n\n\n\n\n\nReading MNIST data in CNTK\n\n\nNotebook 103B on CNTK GitHub\n\n\nVideo\n\n\n\n\n\n\nCreating and training a logistic regression classifier\n\n\nNotebook 103B on CNTK GitHub\n\n\nVideo\n\n\n\n\n\n\nPredicting on data\n\n\nNotebook 103B on CNTK GitHub\n\n\nVideo\n\n\n\n\n\n\nTraining and testing a Multilayer Perceptron\n\n\nNotebook 103C on CNTK GitHub\n\n\nVideo\n\n\n\n\n\n\nReading MNIST data in CNTK (CNN version)\n\n\nNotebook 103D on CNTK GitHub\n\n\nVideo\n\n\n\n\n\n\nUnderstanding CNN filters, strides and padding\n\n\nNotebook 103D on CNTK GitHub\n\n\nVideo\n\n\n\n\n\n\nBuild CNN model, understand layers and number of parameters\n\n\nNotebook 103D on CNTK GitHub\n\n\nVideo\n\n\n\n\n\n\nTraining and evaluating CNN model\n\n\nNotebook 103D on CNTK GitHub\n\n\nVideo\n\n\n\n\n\n\n\n\n\n\nUse these notebooks for free online:  \nCNTK Tutorials on Azure Notebooks",
            "title": "Preparation"
        },
        {
            "location": "/level2/level2_prep/#level-2-preparation",
            "text": "Now it's time to really learn about CNTK and classifiers such as logistic regression, multilayer perceptron, and convolutional network (CNN/ConvNet) classifiers.  The MNIST hand-written digits dataset is used in the following course to classify grey-scale images of digits.  We'll use this code in our Challenge section so go ahead and get familiar with it now by taking this course.  Work through the first four modules of the free Deep Learning Explained edX  course .  Each module should take 1-2 hours each.   Learn concepts around neural networks for image applications.  List the differences between a Convolutional (ConvNet/CNN) and regular Dense Neural Network.  List and give examples of the tunable hyperparameters one can find in a ConvNet.\n...",
            "title": "Level 2 Preparation"
        },
        {
            "location": "/level2/level2_prep/#for-quick-reference-mnist-digits-and-cntk-notebooks-and-videos",
            "text": "Below are links to some of the Jupyter notebooks used in the edX Deep Learning Explained course (linked to above) using the MNIST hand-written digits dataset.  Included are links to accompanying videos by Microsoft data scientists around this example.  They are meant to be worked on in order, each tutorial building on the previous.  Ideally, you will have also watched the accompanying lectures from the course.     Topic  Tutorial on Jupyter  Video Link      Loading MNIST data  Notebook 103A on CNTK GitHub  Video    Reading MNIST data in CNTK  Notebook 103B on CNTK GitHub  Video    Creating and training a logistic regression classifier  Notebook 103B on CNTK GitHub  Video    Predicting on data  Notebook 103B on CNTK GitHub  Video    Training and testing a Multilayer Perceptron  Notebook 103C on CNTK GitHub  Video    Reading MNIST data in CNTK (CNN version)  Notebook 103D on CNTK GitHub  Video    Understanding CNN filters, strides and padding  Notebook 103D on CNTK GitHub  Video    Build CNN model, understand layers and number of parameters  Notebook 103D on CNTK GitHub  Video    Training and evaluating CNN model  Notebook 103D on CNTK GitHub  Video      Use these notebooks for free online:   CNTK Tutorials on Azure Notebooks",
            "title": "For Quick Reference - MNIST Digits and CNTK Notebooks and Videos"
        },
        {
            "location": "/level2/level2_practice/",
            "text": "Level 2 Challenge\n\n\nIn this intermediate Challenge, you'll apply what you've learned in the edX Deep Learning Explained course, leveraging the Jupyter notebooks you became familiar with in the course.  You'll start exploring the CIFAR-10 dataset along with other datsets in CNTK and TensorFlow.\n\n\nAdapt Deep Learning Explained CNTK Notebooks\n\n\nImage Classification\n\n\nHere you'll adapt the Jupyter notebooks from the edX course - using the DLVM as the notebook server.  If you have a GPU at home, you may go ahead and use it, just be sure to follow the install instructions for CNTK in the \nAdvanced section\n.\n\n\n\n\nGet the CIFAR-10 dataset (in CNTK format)\n\n\nSSH into your DLVM (\nDoc\n - need to add 'azureuser' to the ssh command however!  Note, you can also use the VM through a Unix Desktop by following this \nDoc\n)\n\n\nssh azureuser@<your VMs public ip here\n (e.g. \nssh azureuser@52.174.34.95\n, which you can get from the Azure portal, portal.azure.com)\n\n\ncd\n into the \nnotebooks\n folder\n\n\nClone the CNTK Github repo\n\n\ncd CNTK/Examples/Image/DataSets/CIFAR-10/\n to go to the data folder where the download script lives\n\n\nRun the download script: \npython install_cifar10.py\n (this might take some time as it's creating the CNTK text files as well as image files from the original Toronto CIFAR 10 archived dataset)\n\n\n\n\n\n\nNow let's begin working with some code.  Log into the Jupyter server on the DLVM - from any browser (note: you'll need to agree to keep going to this site despite the certificate warning - don't worry, this is normal)\n\n\nPoint your browser to \nhttps://<VM DNS name or IP Address>:8000/\n\" (\nDoc\n)\n\n\nIf this notebook is not familiar to you go back to the Preparation section and watch the videos \nhere\n.\n\n\n\n\n\n\nOpen \nCNTK_103D_MNIST_ConvolutionalNeuralNetwork.ipynb\n (or better yet, open a copy you've made on the VM) - this will be the CNN notebook you modify to fit the CIFAR-10 dataset (instead of MNIST), remembering that your data is now at \n../Examples/Image/DataSets/CIFAR-10/\n.\n\n\nModify the notebook to work with the CIFAR-10\n\n\nRemember you're working with RGB images instead of grayscale\n\n\n\n\n\n\nWhat is the resulting average test error?  Why is this value so different from the MNIST result?  What hyperparameters can you modify to fix this?\n\n\n\n\nExtra Credit\n\n\n\n\nGo online and find 5 png's of cats and dogs.  Reshape them and pad them to be 32x32 pixels using the Python Pillow library (see \nImageOps\n).  Convert them to the proper CNTK text format.  Test the network with these, following the guidelines and lessons you learned in the edX course.  Now find an image of a coconut or lime and test the network with this.  What is wrong with using a food image?\n\n\nCreate a new label called \"food\" and add this \nfruit dataset\n, leaving some out of training for testing.  Try your coconut image again.  What if now you tested with a hot dog image?\n\n\n\n\nTransfer Learning on the Deep Learning Virtual Machine with CNTK\n\n\nHere, for ease of use and speed we'll use Transfer Learning as well.\n\n\n\n\nRun \nthis\n script on the command line on your DLVM, to train your classifier with Transfer Learning (the base model here is \nResNet\n).\n\n\n\n\nTaste of TensorFlow\n\n\nEasy:  Run this TensorFlow script to classify a new image (this uses a pretrained Inception V3 model):\n\n\n\n\nhttps://www.tensorflow.org/tutorials/image_recognition\n\n\n\n\nIntermediate: Perform this TensorFlow CNN Tutorial from Google:\n\n\n\n\nhttps://www.tensorflow.org/tutorials/deep_cnn\n\n\n\n\nAdvanced:  Modify this MNIST CNN TensorFlow tutorial for use with the CIFAR-10 dataset:\n\n\n\n\nhttp://adventuresinmachinelearning.com/convolutional-neural-networks-tutorial-tensorflow/\n\n\n\n\nWant More?\n\n\nCheck out Rodrigo Benenson's \nblog\n to find out the best algorithm for classifying with CIFAR-10 and implement it.  May the force be with you.\n\n\nAdditional Help\n\n\n\n\nStackOverflow with \ncntk\n or \ntensorflow\n tag\n\n\nFor CNTK specific help you may send your questions to \ncntkhelp@microsoft.com\n.",
            "title": "Practice"
        },
        {
            "location": "/level2/level2_practice/#level-2-challenge",
            "text": "In this intermediate Challenge, you'll apply what you've learned in the edX Deep Learning Explained course, leveraging the Jupyter notebooks you became familiar with in the course.  You'll start exploring the CIFAR-10 dataset along with other datsets in CNTK and TensorFlow.",
            "title": "Level 2 Challenge"
        },
        {
            "location": "/level2/level2_practice/#adapt-deep-learning-explained-cntk-notebooks",
            "text": "",
            "title": "Adapt Deep Learning Explained CNTK Notebooks"
        },
        {
            "location": "/level2/level2_practice/#image-classification",
            "text": "Here you'll adapt the Jupyter notebooks from the edX course - using the DLVM as the notebook server.  If you have a GPU at home, you may go ahead and use it, just be sure to follow the install instructions for CNTK in the  Advanced section .   Get the CIFAR-10 dataset (in CNTK format)  SSH into your DLVM ( Doc  - need to add 'azureuser' to the ssh command however!  Note, you can also use the VM through a Unix Desktop by following this  Doc )  ssh azureuser@<your VMs public ip here  (e.g.  ssh azureuser@52.174.34.95 , which you can get from the Azure portal, portal.azure.com)  cd  into the  notebooks  folder  Clone the CNTK Github repo  cd CNTK/Examples/Image/DataSets/CIFAR-10/  to go to the data folder where the download script lives  Run the download script:  python install_cifar10.py  (this might take some time as it's creating the CNTK text files as well as image files from the original Toronto CIFAR 10 archived dataset)    Now let's begin working with some code.  Log into the Jupyter server on the DLVM - from any browser (note: you'll need to agree to keep going to this site despite the certificate warning - don't worry, this is normal)  Point your browser to  https://<VM DNS name or IP Address>:8000/ \" ( Doc )  If this notebook is not familiar to you go back to the Preparation section and watch the videos  here .    Open  CNTK_103D_MNIST_ConvolutionalNeuralNetwork.ipynb  (or better yet, open a copy you've made on the VM) - this will be the CNN notebook you modify to fit the CIFAR-10 dataset (instead of MNIST), remembering that your data is now at  ../Examples/Image/DataSets/CIFAR-10/ .  Modify the notebook to work with the CIFAR-10  Remember you're working with RGB images instead of grayscale    What is the resulting average test error?  Why is this value so different from the MNIST result?  What hyperparameters can you modify to fix this?",
            "title": "Image Classification"
        },
        {
            "location": "/level2/level2_practice/#extra-credit",
            "text": "Go online and find 5 png's of cats and dogs.  Reshape them and pad them to be 32x32 pixels using the Python Pillow library (see  ImageOps ).  Convert them to the proper CNTK text format.  Test the network with these, following the guidelines and lessons you learned in the edX course.  Now find an image of a coconut or lime and test the network with this.  What is wrong with using a food image?  Create a new label called \"food\" and add this  fruit dataset , leaving some out of training for testing.  Try your coconut image again.  What if now you tested with a hot dog image?",
            "title": "Extra Credit"
        },
        {
            "location": "/level2/level2_practice/#transfer-learning-on-the-deep-learning-virtual-machine-with-cntk",
            "text": "Here, for ease of use and speed we'll use Transfer Learning as well.   Run  this  script on the command line on your DLVM, to train your classifier with Transfer Learning (the base model here is  ResNet ).",
            "title": "Transfer Learning on the Deep Learning Virtual Machine with CNTK"
        },
        {
            "location": "/level2/level2_practice/#taste-of-tensorflow",
            "text": "Easy:  Run this TensorFlow script to classify a new image (this uses a pretrained Inception V3 model):   https://www.tensorflow.org/tutorials/image_recognition   Intermediate: Perform this TensorFlow CNN Tutorial from Google:   https://www.tensorflow.org/tutorials/deep_cnn   Advanced:  Modify this MNIST CNN TensorFlow tutorial for use with the CIFAR-10 dataset:   http://adventuresinmachinelearning.com/convolutional-neural-networks-tutorial-tensorflow/",
            "title": "Taste of TensorFlow"
        },
        {
            "location": "/level2/level2_practice/#want-more",
            "text": "Check out Rodrigo Benenson's  blog  to find out the best algorithm for classifying with CIFAR-10 and implement it.  May the force be with you.",
            "title": "Want More?"
        },
        {
            "location": "/level2/level2_practice/#additional-help",
            "text": "StackOverflow with  cntk  or  tensorflow  tag  For CNTK specific help you may send your questions to  cntkhelp@microsoft.com .",
            "title": "Additional Help"
        },
        {
            "location": "/level3/level3_setup/",
            "text": "Setup\n\n\nYou'll be doing most thing locally in this Advanced Challenge.\n\n\nGetting your Environment Set Up\n\n\nHardware\n\n\nThese are some highly rated suggestions.  You may of course try out the Practice section on a CPU machine.  There's a cloud option below as well.\n\n\nComputer-Laptop\n\n\nAnything with a NVIDIA GTX 1060 (GPU) is good if you travel a lot or cannot necessarily depend on wifi.\n\n\n\n\nE.g.:  \nhttps://www.razerzone.com/gaming-systems/razer-blade-pro\n - plan to get a 1060 w/ 256ssd + 2tb spinner\n\n\nGTX 1080 (extra $2k; only get if this is your primary machine and you travel a lot/have spotty wifi).\n\n\n\n\nComputer-Desktop\n\n\nAny gaming desktop with a min GTX 1080.\u00a0\n\n\n\n\nAlt 1: Custom built.\u00a0 If you go this route -> Add up your GPU ram, multiply by 2 for your min RAM.\u00a0 Get a CPU w/ 48 lanes (so you can go 2 GPUs later).\n\n\nAlt 2: \nhttps://lambdal.com/products/quad\n (this is probably over kill honestly, and your electricity bill might double.\u00a0 Will make a great space heater)\n\n\n\n\nComputer-Remote\n\n\nUse Azure and set up a jupyter notebook.\u00a0 This takes more learning and understanding but is the cheapest getting started option.\n\n\nIt's suggested to provision a new NC-6 (or NC12) DSVM on Ubuntu, updating everything, installing the packages, adding a 1TB data disk and kicking off a password protected Jupyter Notebook in a tmux session.\u00a0 DO NOT put sensitive data on this.\u00a0 It has open ports, admin rights to the system, is password protected only and it's not believed to use SSL unless you set up a certificate.\u00a0 There are other more secure options, though they are more advanced and not covered in this getting started.\n\n\nIoT-Test_Device\n\n\nRaspberry Pi v3, Nvidia TX-1 or Nvidia TX-2.\u00a0 If you are feeling adventurous get a few arduinos as well.\n\n\nSoftware\n\n\n\n\nDocker for Mac or Docker for Windows (avoid Toolbox)\n\n\nAnaconda\n\n\nIf you have a GPU\n\n\nGo to \nCuda Downloads\n\n\nJoin Nvidia Developer program\n\n\nUpdate your GPU drivers\n\n\nInstall Cuda & Cudnn\n\n\n\n\n\n\nInstall your packages\n\n\nOpen an admin cmd prompt\n\n\nPip install \nplotly\n (most other packages come with Anaconda)\n\n\nPip install the latest 3.6 GPU-1bit-SGD (if you got a GPU otherwise install CPU version)\n\n\nCNTK 2.2\n\n\nAs of today this is: \npip install https://cntk.ai/PythonWheel/GPU-1bit-SGD/cntk-2.2-cp36-cp36m-win_amd64.whl\n\n\n\n\n\n\n\n\n\n\nInstall \nAzure ML Workbench\n.\n\n\n\n\nGood Idea:\n\n\n\n\nStackOverflow account",
            "title": "Setup"
        },
        {
            "location": "/level3/level3_setup/#setup",
            "text": "You'll be doing most thing locally in this Advanced Challenge.",
            "title": "Setup"
        },
        {
            "location": "/level3/level3_setup/#getting-your-environment-set-up",
            "text": "",
            "title": "Getting your Environment Set Up"
        },
        {
            "location": "/level3/level3_setup/#hardware",
            "text": "These are some highly rated suggestions.  You may of course try out the Practice section on a CPU machine.  There's a cloud option below as well.",
            "title": "Hardware"
        },
        {
            "location": "/level3/level3_setup/#computer-laptop",
            "text": "Anything with a NVIDIA GTX 1060 (GPU) is good if you travel a lot or cannot necessarily depend on wifi.   E.g.:   https://www.razerzone.com/gaming-systems/razer-blade-pro  - plan to get a 1060 w/ 256ssd + 2tb spinner  GTX 1080 (extra $2k; only get if this is your primary machine and you travel a lot/have spotty wifi).",
            "title": "Computer-Laptop"
        },
        {
            "location": "/level3/level3_setup/#computer-desktop",
            "text": "Any gaming desktop with a min GTX 1080.\u00a0   Alt 1: Custom built.\u00a0 If you go this route -> Add up your GPU ram, multiply by 2 for your min RAM.\u00a0 Get a CPU w/ 48 lanes (so you can go 2 GPUs later).  Alt 2:  https://lambdal.com/products/quad  (this is probably over kill honestly, and your electricity bill might double.\u00a0 Will make a great space heater)",
            "title": "Computer-Desktop"
        },
        {
            "location": "/level3/level3_setup/#computer-remote",
            "text": "Use Azure and set up a jupyter notebook.\u00a0 This takes more learning and understanding but is the cheapest getting started option.  It's suggested to provision a new NC-6 (or NC12) DSVM on Ubuntu, updating everything, installing the packages, adding a 1TB data disk and kicking off a password protected Jupyter Notebook in a tmux session.\u00a0 DO NOT put sensitive data on this.\u00a0 It has open ports, admin rights to the system, is password protected only and it's not believed to use SSL unless you set up a certificate.\u00a0 There are other more secure options, though they are more advanced and not covered in this getting started.",
            "title": "Computer-Remote"
        },
        {
            "location": "/level3/level3_setup/#iot-test_device",
            "text": "Raspberry Pi v3, Nvidia TX-1 or Nvidia TX-2.\u00a0 If you are feeling adventurous get a few arduinos as well.",
            "title": "IoT-Test_Device"
        },
        {
            "location": "/level3/level3_setup/#software",
            "text": "Docker for Mac or Docker for Windows (avoid Toolbox)  Anaconda  If you have a GPU  Go to  Cuda Downloads  Join Nvidia Developer program  Update your GPU drivers  Install Cuda & Cudnn    Install your packages  Open an admin cmd prompt  Pip install  plotly  (most other packages come with Anaconda)  Pip install the latest 3.6 GPU-1bit-SGD (if you got a GPU otherwise install CPU version)  CNTK 2.2  As of today this is:  pip install https://cntk.ai/PythonWheel/GPU-1bit-SGD/cntk-2.2-cp36-cp36m-win_amd64.whl      Install  Azure ML Workbench .   Good Idea:   StackOverflow account",
            "title": "Software"
        },
        {
            "location": "/level3/level3_prep/",
            "text": "Level 3 Preparation\n\n\nYou might find \nthese videos\n from \nthis\n CNN course out of Stanford useful.\n\n\nMore to come.",
            "title": "Preparation"
        },
        {
            "location": "/level3/level3_prep/#level-3-preparation",
            "text": "You might find  these videos  from  this  CNN course out of Stanford useful.  More to come.",
            "title": "Level 3 Preparation"
        },
        {
            "location": "/level3/level3_practice/",
            "text": "Level 3 Challenge\n\n\nIn this advanced Challenge, the instructions will be a little more vague and you'll need to go figure find out much on your own, part of the learning and challenge.\n\n\n\n\nThis problem set is adapted from a Custom ML Resources document written by a colleague.\n\n\n\n\nWhy do this task\n:\u00a0 Usually, beginner tutorials around ML and neural networks begin with classifying hand-written digits from the MNIST dataset.  We are going to begin with something more challenging and much of it will be dealing with data and data formats.  This is to simulate how life will likely be in real life and it's hoped you will learn how to create machine learning models more effectively and quickly in the real world.\u00a0The reason to work through the following is:\n\n\n\n\nIt will force you to read and learn from scratch.\u00a0 You will learn the different label file formats, deserializers and how things compute.\u00a0\n\n\nFor energy/manufacturing you will get .png or .jpg or .tiff files and not stuff already in the perfect format.\u00a0\n\n\nLearning this will hopefully help you understand the concept of \u201cData Packing\u201d.\u00a0\n\n\nThis is not the simplest way, but it forces greater learning.\n\n\n\n\nWorking with CNTK Locally (DLVM is also OK)\n\n\nUse the CNTK Manual as reference: \nCNTK Manual on GitHub\n\n\nThis is focusing for the Energy/Manufacturing Vertical.\n\n\n\n\nUnderstand Label Files & Mini Batch Sources:\n\n\nCTF & Image: \nhttp://dacrook.com/complex-neural-network-data-modelling-with-cntk/\n\n\nSequence: \nhttp://dacrook.com/deep-learning-match-making-with-recurrent-networks/\n\n\n\n\n\n\nImage Classification:\n\n\nStart w/ CIFAR 10 for image classification using a Jupyter Notebook (use \nCNTK Manual on GitHub\n)\n\n\nGet Data from here: \nCIFAR-10 data\n\n\nStart w/ a CTF deserializer\n\n\nUse Image library w/ numpy and CNTK's io libraries to write a ctf file containing the data in flattened arrays\n\n\n\n\n\n\nUse the Image deserializer next\n\n\nTry out a few transforms.\u00a0 You will have to read the CNTK docs pages for transforms. \nCNTK transforms\n\n\n\n\n\n\nMake sure you also create an example for \ninference\n.\n\n\nUse Scikit-learns\u2019s confusion matrix and classification_report to generate metrics.\n\n\nScikit-learn's confusion matrix\n\n\nScikit-learn's classification report\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAzure ML Workbench\n\n\n\n\n\n\nDo the same thing w/ Azure ML Workbench\n\n\n\n\nSet up\n\n\nCreate a workspace\n\n\nCreate a git repo in VSTS\n\n\nCreate a project linked to the repo\n\n\nRe-write as a single training script and execute via docker locally.\n\n\nAdd in Azure ML Workbench\u2019s logging apis.\n\n\nTry out a Convolutional Network\n\n\nUse the Azure ML Workbench Operationalization CLI to create a container.\n\n\nCreate a local container\n\n\nPull the local container and test locally\n\n\nDeploy a real time container to Azure Container Services\n\n\nTest against this.\n\n\nTIP:\u00a0 You will either send the image via the body as an array of float32 or as a byte64 encoded string.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDo the same exact exercise with CoCo: \nhttp://cocodataset.org/#home\n\n\n\n\nWhy do you think you get bad results?\n\n\n\n\n\n\nUse the Out of Box Faster-RCNN solution w/ CNTK and CoCo\n\n\n\n\nTaste of TensorFlow\n\n\nTrain a CNN on the CIFAR-10 dataset as in this \nTutorial\n.\n\n\nKey Learnings\n\n\nObject detection v.s. Classification, Data Prep and pipelines.\n\n\nPlaces to go for Help\n\n\nIf you run into trouble, email CNTK Help \ncntkhelp@microsoft.com\n and also create a stack overflow with tag \ncntk\n, then send the link to SO to CNTK Help.  Alternatively, create an Issue on the CNTK GitHub repo.",
            "title": "Practice"
        },
        {
            "location": "/level3/level3_practice/#level-3-challenge",
            "text": "In this advanced Challenge, the instructions will be a little more vague and you'll need to go figure find out much on your own, part of the learning and challenge.   This problem set is adapted from a Custom ML Resources document written by a colleague.   Why do this task :\u00a0 Usually, beginner tutorials around ML and neural networks begin with classifying hand-written digits from the MNIST dataset.  We are going to begin with something more challenging and much of it will be dealing with data and data formats.  This is to simulate how life will likely be in real life and it's hoped you will learn how to create machine learning models more effectively and quickly in the real world.\u00a0The reason to work through the following is:   It will force you to read and learn from scratch.\u00a0 You will learn the different label file formats, deserializers and how things compute.\u00a0  For energy/manufacturing you will get .png or .jpg or .tiff files and not stuff already in the perfect format.\u00a0  Learning this will hopefully help you understand the concept of \u201cData Packing\u201d.\u00a0  This is not the simplest way, but it forces greater learning.",
            "title": "Level 3 Challenge"
        },
        {
            "location": "/level3/level3_practice/#working-with-cntk-locally-dlvm-is-also-ok",
            "text": "Use the CNTK Manual as reference:  CNTK Manual on GitHub  This is focusing for the Energy/Manufacturing Vertical.   Understand Label Files & Mini Batch Sources:  CTF & Image:  http://dacrook.com/complex-neural-network-data-modelling-with-cntk/  Sequence:  http://dacrook.com/deep-learning-match-making-with-recurrent-networks/    Image Classification:  Start w/ CIFAR 10 for image classification using a Jupyter Notebook (use  CNTK Manual on GitHub )  Get Data from here:  CIFAR-10 data  Start w/ a CTF deserializer  Use Image library w/ numpy and CNTK's io libraries to write a ctf file containing the data in flattened arrays    Use the Image deserializer next  Try out a few transforms.\u00a0 You will have to read the CNTK docs pages for transforms.  CNTK transforms    Make sure you also create an example for  inference .  Use Scikit-learns\u2019s confusion matrix and classification_report to generate metrics.  Scikit-learn's confusion matrix  Scikit-learn's classification report",
            "title": "Working with CNTK Locally (DLVM is also OK)"
        },
        {
            "location": "/level3/level3_practice/#azure-ml-workbench",
            "text": "Do the same thing w/ Azure ML Workbench   Set up  Create a workspace  Create a git repo in VSTS  Create a project linked to the repo  Re-write as a single training script and execute via docker locally.  Add in Azure ML Workbench\u2019s logging apis.  Try out a Convolutional Network  Use the Azure ML Workbench Operationalization CLI to create a container.  Create a local container  Pull the local container and test locally  Deploy a real time container to Azure Container Services  Test against this.  TIP:\u00a0 You will either send the image via the body as an array of float32 or as a byte64 encoded string.         Do the same exact exercise with CoCo:  http://cocodataset.org/#home   Why do you think you get bad results?    Use the Out of Box Faster-RCNN solution w/ CNTK and CoCo",
            "title": "Azure ML Workbench"
        },
        {
            "location": "/level3/level3_practice/#taste-of-tensorflow",
            "text": "Train a CNN on the CIFAR-10 dataset as in this  Tutorial .",
            "title": "Taste of TensorFlow"
        },
        {
            "location": "/level3/level3_practice/#key-learnings",
            "text": "Object detection v.s. Classification, Data Prep and pipelines.",
            "title": "Key Learnings"
        },
        {
            "location": "/level3/level3_practice/#places-to-go-for-help",
            "text": "If you run into trouble, email CNTK Help  cntkhelp@microsoft.com  and also create a stack overflow with tag  cntk , then send the link to SO to CNTK Help.  Alternatively, create an Issue on the CNTK GitHub repo.",
            "title": "Places to go for Help"
        }
    ]
}